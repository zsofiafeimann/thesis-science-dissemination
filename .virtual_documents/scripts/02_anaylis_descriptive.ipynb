


import pandas as pd
import os
import numpy as np
! pip install scikit_posthocs
!pip install seaborn


target_dir = r"C:\Users\Diak\Documents\thesis\thesis-science-dissemination"
os.chdir(target_dir)


# 1.1 Load publication‐level metrics
df_data_2019 = pd.read_csv(
    "cleaned_data/data_2019_clean.csv",
    sep="|",
    parse_dates=["pubdate"],
    low_memory=False
)


df_data_2019.head()


# 1.2 Load author–institution ranking data
df_ranked = pd.read_csv(
    "cleaned_data/ranked_institution_2019.csv",
    sep="|",
    low_memory=False
)


df_ranked.head()


# 1.3 Load author‐level aggregates
df_author = pd.read_csv(
    "cleaned_data/author_clean.csv",
    sep="|",
    low_memory=False
)


df_author.head()





df_merged_public_ranking = pd.merge(
    df_ranked,
    df_data_2019,
    how="left",
    on="doi",
    validate="many_to_many"   # many ranked rows per one publication is expected
)


# Append author-level aggregates
df_merged_all = pd.merge(
    df_merged_public_ranking,
    df_author[['author', 'works_count', 'cited_by_count']],
    how='left',
    on='author'
)


### Quick validation
print("Merged shape:", df_merged_all.shape)
print("Missing publication:", df_merged_all['pubdate'].isnull().sum(), "row")
print("Duplicated doi-author pairs:", df_merged_all.duplicated(subset=['doi','author']).sum())


pd.set_option('display.max_columns', None)


df_merged_all.head()








import os
from pathlib import Path
import matplotlib.pyplot as plt
import matplotlib as mpl
import seaborn as sns

# === helper: automatikus mentés számozva ===
def save_current_figure(folder="results/plots", prefix="plot", ext="png"):
    os.makedirs(folder, exist_ok=True)
    existing = sorted(Path(folder).glob(f"{prefix}_*.{ext}"))
    next_id = len(existing) + 1
    filename = f"{prefix}_{next_id:03d}.{ext}"
    full_path = Path(folder) / filename
    plt.gcf().savefig(full_path, dpi=300, bbox_inches="tight")

# Set general seaborn style
sns.set_style("whitegrid")

# Apply consistent font and layout settings
plt.rcParams.update({
    "figure.figsize": (8, 5),
    "axes.titlesize": 14,
    "axes.labelsize": 12,
    "xtick.labelsize": 10,
    "ytick.labelsize": 10,
    "axes.edgecolor": "gray",
    "axes.linewidth": 1.0,
    "grid.color": "lightgray",
    "grid.linestyle": "--",
    "grid.linewidth": 0.5,
    "legend.fontsize": 10,
    "font.family": "sans-serif",
    "font.sans-serif": ["Arial", "Helvetica"]
})

# === 1. Histogram Plot ===
def plot_hist(data, column, bins=40, title=None, xlabel=None, color=None):
    hist_color = color or sns.color_palette("Dark2")[0]
    plt.figure()
    sns.histplot(
        data[column].dropna(),
        bins=bins,
        kde=False,
        color=hist_color
    )
    plt.title(title or f"Distribution of {column}")
    plt.xlabel(xlabel or column)
    plt.ylabel("Frequency")
    plt.tight_layout()
    ax = plt.gca()
    ax.get_yaxis().set_major_formatter(plt.FuncFormatter(lambda x, loc: f"{int(x):,}"))
    save_current_figure()
    plt.show()

# === 2. Count Plot ===
def plot_countplot(data, column, title=None, xlabel=None):
    plt.figure()
    sns.countplot(data=data, x=column, hue=column, palette='Dark2', legend=False)
    plt.title(title or f"Distribution of {column}")
    plt.xlabel(xlabel or column)
    plt.ylabel("Count")
    plt.tight_layout()
    ax = plt.gca()
    ax.get_yaxis().set_major_formatter(plt.FuncFormatter(lambda x, loc: f"{int(x):,}"))
    save_current_figure()
    plt.show()

# === 3. Box Plot ===
def plot_boxplot(data, column_x, column_y, title=None, xlabel=None, ylabel=None):
    plt.figure(figsize=(8, 6))
    sns.boxplot(data=data, x=column_x, y=column_y, hue=column_x, palette='Dark2')
    plt.title(title or f"{column_y} by {column_x}")
    plt.xlabel(xlabel or column_x)
    plt.ylabel(ylabel or column_y)
    plt.tight_layout()
    ax.get_yaxis().set_major_formatter(plt.FuncFormatter(lambda x, loc: f"{int(x):,}"))
    save_current_figure()
    plt.show()

# === 4. Bar Plot ===
def plot_barplot(data,
                 x_col,
                 y_col,
                 hue_col=None,
                 title=None,
                 xlabel=None,
                 ylabel=None,
                 palette="Dark2",
                 rot=45,
                 distinct_colors=True,
                 format_yaxis=True):

    plt.figure(figsize=(10, 8))

    if hue_col:
        sns.barplot(
            data=data, x=x_col, y=y_col, hue=hue_col,
            palette=palette, legend=True,
            errorbar=None
        )
    else:
        if distinct_colors:
            sns.barplot(
                data=data, x=x_col, y=y_col, hue=x_col,
                palette=palette, legend=False,
                errorbar=None
            )
        else:
            single_color = sns.color_palette(palette)[0]
            sns.barplot(
                data=data, x=x_col, y=y_col, color=single_color,
                errorbar=None
            )

    plt.xticks(rotation=rot, ha="right")
    plt.title(title or f"{y_col} by {x_col}")
    plt.xlabel(xlabel or x_col)
    plt.ylabel(ylabel or y_col)

    if format_yaxis:
        ax = plt.gca()
        ax.get_yaxis().set_major_formatter(plt.FuncFormatter(lambda x, loc: f"{int(x):,}"))

    plt.tight_layout()
    save_current_figure()
    plt.show()

# === 5. Combined bar + line plot ===
def combined_bar_line_plot(
    data,
    x_col,
    bar_y_col,
    line_y_col,
    title="Combined Bar and Line Plot",
    xlabel=None,
    bar_ylabel="Bar Value",
    line_ylabel="Line Value",
    palette="Dark2",
    line_color="orange"
):
    fig, ax1 = plt.subplots(figsize=(8, 5))
    sns.barplot(data=data, x=x_col, y=bar_y_col, hue=x_col, palette=palette, ax=ax1)
    ax1.set_ylabel(bar_ylabel, fontsize=12)
    ax1.set_xlabel(xlabel or x_col, fontsize=12)
    ax1.tick_params(axis='y')
    ax1.grid(axis='y', linestyle='--', linewidth=0.5, color='lightgray')
    ax1.get_yaxis().set_major_formatter(plt.FuncFormatter(lambda x, loc: f"{int(x):,}"))
    ax2 = ax1.twinx()
    ax2.plot(data[x_col], data[line_y_col], color=line_color, marker="o", linewidth=2)
    ax2.set_ylabel(line_ylabel, fontsize=12)
    ax2.tick_params(axis='y')
    ax2.grid(False)
    ax2.get_yaxis().set_major_formatter(plt.FuncFormatter(lambda x, loc: f"{int(x):,}"))
    plt.title(title, fontsize=14)
    fig.tight_layout()
    save_current_figure()
    plt.show()

# === 6. Scatter + Regression line (single- vagy multi-hue) ===
def plot_regplot(data,
                 x_col,
                 y_col,
                 hue_col=None,
                 title=None,
                 xlabel=None,
                 ylabel=None,
                 palette="Dark2",
                 scatter_alpha=0.1,
                 scatter_size=10,
                 line_color=None):
    sns.set_style("whitegrid")
    if hue_col:
        sns.lmplot(
            data=data,
            x=x_col,
            y=y_col,
            hue=hue_col,
            palette=palette,
            scatter_kws={"alpha": scatter_alpha, "s": scatter_size},
            height=6,
            aspect=1.5,
            markers='o',
            ci=None
        )
        plt.title(title or f"{y_col} vs. {x_col} by {hue_col}")
        plt.xlabel(xlabel or x_col)
        plt.ylabel(ylabel or y_col)
        plt.tight_layout()
        save_current_figure()
        plt.show()
    else:
        pal = sns.color_palette(palette)
        scat_col = pal[0]
        reg_col  = line_color or pal[1]
        plt.figure(figsize=(8, 5))
        sns.regplot(
            data=data,
            x=x_col,
            y=y_col,
            scatter_kws={"s": scatter_size, "alpha": scatter_alpha, "color": scat_col},
            line_kws={"color": reg_col},
            ci=None
        )
        plt.title(title or f"{y_col} vs. {x_col}")
        plt.xlabel(xlabel or x_col)
        plt.ylabel(ylabel or y_col)
        plt.tight_layout()
        ax = plt.gca()
        ax.get_yaxis().set_major_formatter(plt.FuncFormatter(lambda x, loc: f"{x:,.0f}"))
        save_current_figure()
        plt.show()





df_merged_all.columns.to_list()


# Plotting the distribution of social visibility scores (raw Altmetric values)
plot_hist(
    df_merged_all,
    column="stot",
    title="Distribution of Social Visibility (Raw)",
    xlabel="Social Visibility (untransformed)"
)





df_merged_all['stot_log1p'] = (df_merged_all['stot'] + 1).apply(np.log)


# === Basic descriptive stats for stot ===
print("=== Social Visibility descriptive statistics ===")
print(df_merged_all['stot'].describe())


# === Basic descriptive stats for stot_log1p ===
print("=== Log-Transformed Social Visibility descriptive statistics ===")
print(df_merged_all['stot_log1p'].describe())


# Plotting the distribution of social visibility scores after log(1 + x) transformation to reduce skewness
plot_hist(
    df_merged_all,
    column="stot_log1p",
    title="Distribution of Log-Transformed Social Visibility",
    xlabel="log(1 + Social Visibility)"
)


# Plotting the distribution of citation counts after log(1 + x) transformation
plot_hist(
    df_merged_all,
    column="cit_log",
    title="Distribution of Log-Transformed Citation Counts",
    xlabel="log(1 + Citation Count)"
)


# === Basic descriptive stats for cited_by_count, author level ===
print(df_merged_all['cited_by_count'].describe())


# Plotting the distribution of author-level citation counts (raw values, not transformed)
plot_hist(
    data=df_merged_all,
    column='cited_by_count',
    title='Distribution of Author-Level Citation Counts',
    xlabel='Number of Citations'
)


df_merged_all['cited_by_log1p'] = np.log1p(df_merged_all['cited_by_count'])


# Plotting the distribution of author-level citation counts after log(1 + x) transformation
plot_hist(
    data=df_merged_all,
    column='cited_by_log1p',
    title='Distribution of Log-Transformed Author-Level Citations',
    xlabel='log(1 + Citations)'
)





# Visualizing the relationship between log-transformed citation counts and social visibility
plot_regplot(
    data=df_merged_all,
    x_col="cit_log",
    y_col="stot_log1p",
    title="Relationship Between Citations and Social Visibility",
    xlabel="log(1 + Citation Count)",
    ylabel="log(1 + Social Visibility)",
    scatter_alpha=0.15,
    scatter_size=12,
    line_color="darkorange"
)





# Pearson (linear correlation)
pearson = df_merged_all[['cit_log', 'stot_log1p']].corr(method='pearson')

# Spearman (rank-correlation)
spearman = df_merged_all[['cit_log', 'stot_log1p']].corr(method='spearman')

print("Pearson correlation:\n", pearson)
print("\nSpearman correlation:\n", spearman)


display(pearson)
display(spearman)








print(df_merged_all['parent_id'].nunique())


# Group by parent_id and sum female/male/unisex counts
gender_counts = df_merged_all.groupby('parent_id')[['female', 'male', 'unisex']].sum().copy()

# Find max value between female and male only
max_vals = gender_counts[['female', 'male']].max(axis=1)
is_female = gender_counts['female'] == max_vals
is_male = gender_counts['male'] == max_vals

# Where only one of them is max -> assign that majority
gender_majority = pd.Series('gender_undetermined_majority', index=gender_counts.index)
gender_majority[is_female & ~is_male] = 'gender_female_majority'
gender_majority[is_male & ~is_female] = 'gender_male_majority'

# Merge back to original df
gender_counts['gender_majority'] = gender_majority
df_merged_all = df_merged_all.merge(
    gender_counts[['gender_majority']].reset_index(),
    on='parent_id',
    how='left'
)


print(df_merged_all[['parent_id', 'gender_majority']].head())


# Absolute counts of gender majority categories across articles
gender_counts = df_merged_all['gender_majority'].value_counts(dropna=False)

# Relative proportions of each category
gender_props = df_merged_all['gender_majority'].value_counts(normalize=True, dropna=False)

# Combine both into a summary DataFrame
gender_summary = pd.DataFrame({
    'count': gender_counts,
    'proportion': gender_props
}).sort_values(by='count', ascending=False)

print("=== Gender Majority Summary: Counts and Proportions ===")
print(gender_summary)


df_gender_filtered = df_merged_all[df_merged_all['gender_majority'].isin(['gender_male_majority', 'gender_female_majority'])]


# Plotting the distribution of gender-majority classification (filtered to only male/female majority)
plot_countplot(
    df_gender_filtered,
    'gender_majority',
    title="Gender Distribution",
    xlabel="Gender majority"
)


# Get descriptive statistics (e.g., mean, std, min, max) for stot_log1p grouped by gender
gender_stats = df_gender_filtered.groupby('gender_majority')['stot_log1p'].describe()

# Print the descriptive statistics
print("=== Descriptive Statistics: log(1 + Social Visibility) by Gender Majority ===")
display(gender_stats)


# Comparing log-transformed social visibility across gender-majority groups
plot_boxplot(
    df_gender_filtered,
    column_x='gender_majority',
    column_y='stot_log1p',
    title="Social Visibility by Gender Majority",
    xlabel="Gender Majority",
    ylabel="log(1 + Social Visibility)"
)


# === ANOVA test: stot_log1p by gender majority ===

import scipy.stats as stats

groups = [
    df_gender_filtered[df_gender_filtered['gender_majority'] == cat]['stot_log1p'].dropna()
    for cat in ['gender_male_majority', 'gender_female_majority']
]

f_stat, p_val = stats.f_oneway(*groups)

print("=== ANOVA: Social Visibility by Gender Majority ===")
print(f"F-statistic: {f_stat:.4f}")
print(f"P-value:    {p_val:.4g}")


# === Kruskal–Wallis Test: stot_log1p by gender majority ===

from scipy.stats import kruskal

female_group = df_gender_filtered[df_gender_filtered['gender_majority'] == 'gender_female_majority']['stot_log1p'].dropna()
male_group = df_gender_filtered[df_gender_filtered['gender_majority'] == 'gender_male_majority']['stot_log1p'].dropna()

kw_stat, kw_p = kruskal(female_group, male_group)

print("=== Kruskal–Wallis Test: Social Visibility by Gender Majority ===")
print(f"H-statistic: {kw_stat:.4f}")
print(f"P-value:     {kw_p:.5f}")


# === Dunn's post-hoc test with Bonferroni correction by gender majority ===

import scikit_posthocs as sp

dunn_results = sp.posthoc_dunn(
    df_gender_filtered,
    val_col='stot_log1p',
    group_col='gender_majority',
    p_adjust='bonferroni'
)

print("=== Dunn's Test Social Visbility by Gender Majority ===")
print(dunn_results)


# === Linear regression model: stot_log1p ~ gender_label ===

import statsmodels.formula.api as smf

model = smf.ols('stot_log1p ~ C(gender_majority)', data=df_gender_filtered).fit()

print("=== Linear Regression: log(1 + Social Visibility) ~ Gender Majority ===")
print(model.summary())





ethnicity_counts = df_merged_all['ethnicity_majority'].value_counts()

print("=== Ethnicity categories and their frequencies ===")
print(ethnicity_counts)


ethnicity_props = df_merged_all['ethnicity_majority'].value_counts(normalize=True) * 100

ethnicity_percent = ethnicity_props.round(2).reset_index()
ethnicity_percent.columns = ['ethnicity_majority', 'percentage']

print("=== Ethnicity Majority Group Percentages ===")
print(ethnicity_percent)


# Get descriptive statistics (e.g., mean, std, min, max) for stot_log1p grouped by gender
ethnicity_visibility = df_merged_all.groupby('ethnicity_majority')['stot_log1p'].agg(['count', 'mean', 'std']).round(3)

# Print the descriptive statistics
print("=== Descriptive Statistics: log(1 + Social Visibility) by Ethnicity Majority Group ===")
display(ethnicity_visibility.sort_values(by='mean', ascending=False))


# === ANOVA test: stot_log1p by ethnicity majority ===
eth_groups = [
    df_merged_all[df_merged_all['ethnicity_majority'] == cat]['stot_log1p'].dropna() 
    for cat in df_merged_all['ethnicity_majority'].unique()
]

f_stat_eth, p_val_eth = stats.f_oneway(*eth_groups)

print("=== ANOVA: Social Visibility by Ethnicity ===")
print(f"F-statistic: {f_stat_eth:.4f}")
print(f"P-value:    {p_val_eth:.4g}")


# === Kruskal–Wallis Test: stot_log1p by ethnicity majority ===
ethnicity_groups = [
    df_merged_all[df_merged_all['ethnicity_majority'] == eth]['stot_log1p'].dropna()
    for eth in df_merged_all['ethnicity_majority'].unique()
]

# Kruskal–Wallis
kw_stat, kw_pval = kruskal(*ethnicity_groups)

print("=== Kruskal–Wallis Test: Social Visibility by Ethnicity ===")
print(f"H-statistic: {kw_stat:.4f}")
print(f"P-value:     {kw_pval:.5f}")


# === Dunn's post-hoc test with Bonferroni correction by ethnicity majority ===
dunn_ethnicity = sp.posthoc_dunn(
    df_merged_all,
    val_col='stot_log1p',
    group_col='ethnicity_majority',
    p_adjust='bonferroni'
)

# Display the p-value matrix
print("=== Dunn's Test: Social Visibility by Ethnicit ===")
print(dunn_ethnicity.round(5))


# === Linear regression model: stot_log1p ~ ethnicity_majority ===
print("=== Linear Regression: log(1 + Social Visibility) ~ Ethnicity Majority ===")

# Run OLS regression with categorical predictor
ethnicity_model = smf.ols('stot_log1p ~ C(ethnicity_majority)', data=df_merged_all).fit()

# Display summary
print(ethnicity_model.summary())





# Define all Altmetric platform columns
altmetric_cols = [
    'blogs', 'book_reviews', 'f1000', 'facebook', 'googleplus', 'linkedin',
    'misc', 'news', 'patent', 'peer_reviews', 'pinterest', 'policy',
    'qa', 'reddit', 'syllabi', 'twitter', 'video', 'weibo', 'wikipedia'
]

# Compute overall descriptive statistics for each platform
platform_stats = df_merged_all[altmetric_cols].agg(['count', 'mean', 'std', 'median', 'max']).T
platform_stats['pct_mentioned'] = (df_merged_all[altmetric_cols] > 0).sum() / len(df_merged_all) * 100
platform_stats = platform_stats.rename(columns={'median': '50%'}).round({'mean':2, 'std':2, '50%':0, 'max':0, 'pct_mentioned':2})

print("Overall statistics for all Altmetric platforms:")
display(platform_stats)


# Select key platforms with more than 1% of papers mentioned
key_platforms = platform_stats.index[platform_stats['pct_mentioned'] > 1].tolist()
print("\nKey platforms (>1% mentioned):", key_platforms)


# Create binary indicators for all key platforms on the full dataset
for platform in key_platforms:
    df_merged_all[f'{platform}_binary'] = (df_merged_all[platform] > 0).astype(int)

# Show overall usage again for all key platforms (on the full df_merged_all)
for platform in key_platforms:
    counts = df_merged_all[f'{platform}_binary'].value_counts().sort_index()
    pct    = df_merged_all[f'{platform}_binary'].value_counts(normalize=True).sort_index() * 100
    print(f"\n{platform.capitalize()} overall usage:")
    print(f"  Not mentioned (0): {counts[0]} ({pct[0]:.2f}%)")
    print(f"  Mentioned     (1): {counts[1]} ({pct[1]:.2f}%)")


# Create a list to store actual mention counts
usage_data = []

# Loop through key platforms and get counts
for platform in key_platforms:
    binary_col = f"{platform}_binary"
    mentioned = df_merged_all[binary_col].sum()
    usage_data.append((platform.capitalize(), mentioned))

# Create DataFrame with counts
usage_df = (
    pd.DataFrame(usage_data, columns=['Platform', 'Mentioned (count)'])
    .sort_values('Mentioned (count)', ascending=False)
    .reset_index(drop=True)
)


# Plotting the number of article mentions across the top 5 online platforms (aggregated across all institutions)
plot_barplot(
    data=usage_df,
    x_col='Platform',
    y_col='Mentioned (count)',
    title='Top 5 Platform Mentions',
    xlabel='Platform',
    ylabel='Number of Articles Mentioned'
)


usage_data = []

for platform in key_platforms:
    pct = df_merged_all[f"{platform}_binary"].mean() * 100
    usage_data.append((platform.capitalize(), pct))

usage_df = (
    pd.DataFrame(usage_data, columns=['Platform', 'Mentioned (%)'])
    .sort_values('Mentioned (%)', ascending=False)
    .reset_index(drop=True)  # optional: reset index nicely
)


# Collect usage data for each platform
plot_barplot(
    data=usage_df,
    x_col='Platform',
    y_col='Mentioned (%)',
    title='Overall Platform Mention Rates (%)',
    xlabel='Platform',
    ylabel='Percentage of Articles Mentioned'
)


# Crosstab platform overlap on the full dataset
pairs = [('twitter','facebook'), ('twitter','news'), ('twitter','blogs'),
         ('facebook','news'), ('facebook','blogs'), ('news','blogs')]

for p1, p2 in pairs:
    ct = pd.crosstab(
        df_merged_all[f'{p1}_binary'],
        df_merged_all[f'{p2}_binary'],
        normalize='index'
    ) * 100
    print(f"\nOverlap: {p1.capitalize()} vs {p2.capitalize()} (%)")
    print(ct.round(2))


import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns

# Define the platform pairs
pairs = [('twitter', 'facebook'), ('twitter', 'news'), ('twitter', 'blogs'),
         ('facebook', 'news'), ('facebook', 'blogs'), ('news', 'blogs')]

# Create a dataframe to store the overlap data
overlap_data = []

# Calculate normalized crosstab (row-wise %) for each pair
for p1, p2 in pairs:
    ct = pd.crosstab(
        df_merged_all[f'{p1}_binary'],
        df_merged_all[f'{p2}_binary'],
        normalize='index'
    ) * 100

    # Append both directions (0 -> 1 and 1 -> 1)
    overlap_data.append({
        'Platform Pair': f'{p1.capitalize()} -> {p2.capitalize()}',
        'Overlap (%)': ct.loc[1, 1] if 1 in ct.index and 1 in ct.columns else 0
    })

# Convert to DataFrame
overlap_df = pd.DataFrame(overlap_data)

# Plot the platform overlap using the custom function
plot_barplot(
    data=overlap_df,
    x_col='Platform Pair',
    y_col='Overlap (%)',
    title='Platform Overlap (Normalized by Row %)',
    xlabel='Platform Pair',
    ylabel='Percentage of Articles Mentioned on Both Platforms'
)


df_merged_all['twitter_binary'] = (df_merged_all['twitter'] > 0).astype(int)
df_merged_all['wikipedia_binary'] = (df_merged_all['wikipedia'] > 0).astype(int)


# Twitter statisztika
twitter_citlog_stats = df_merged_all.groupby('twitter_binary')['cit_log'].describe()

# Wikipedia statisztika
wiki_citlog_stats = df_merged_all.groupby('wikipedia_binary')['cit_log'].describe()


# Visualizing the effect of Twitter mentions on log-transformed citation counts
sns.boxplot(
    data=df_merged_all,
    x='twitter_binary',
    y='cit_log',
    hue='twitter_binary',
    palette="Dark2",
    legend=False
)
plt.title('Log Citations by Twitter Mention')
plt.xlabel('Mentioned on Twitter (0=No, 1=Yes)')
plt.ylabel('log(1 + Citation Count)')
plt.tight_layout()
plt.show()


# Linear regression model of the number of Twitter mentions on log-transformed citations
print("=== Linear Regression: log(1 + Citations) ~ Twitter Mentions ===")

import statsmodels.api as sm

# Regress cit_log on number of Twitter mentions
X = df_merged_all['twitter']
y = df_merged_all['cit_log']

X = sm.add_constant(X)  # add intercept
model = sm.OLS(y, X).fit()

print(model.summary())


# Create binary column for Wikipedia mentions
df_merged_all['wikipedia_binary'] = (df_merged_all['wikipedia'] > 0).astype(int)


# Linear regression model the effect of Wikipedia mentions on log-transformed citations
print("=== Linear Regression: log(1 + Citations) ~ Wikipedia Mentions ===")

# Define independent and dependent variables
X = df_merged_all['wikipedia']
y = df_merged_all['cit_log']

# Add constant (intercept) to the model
X = sm.add_constant(X)

# Fit linear regression model
model_wiki = sm.OLS(y, X).fit()

# Print summary
print(model_wiki.summary())


# Count of total and mentioned articles for Twitter and Wikipedia
total_articles = len(df_merged_all)

mention_summary = pd.DataFrame({
    'Platform': ['Twitter', 'Wikipedia'],
    'Mentioned': [
        df_merged_all['twitter_binary'].sum(),
        df_merged_all['wikipedia_binary'].sum()
    ]
})

# Calculate proportion (percentage)
mention_summary['Mentioned (%)'] = (
    mention_summary['Mentioned'] / total_articles * 100
).round(2)

# Display the result
print("=== Number and percentage of articles mentioned per platform ===")
print(mention_summary.to_string(index=False))


# Plotting the number of articles mentioned on each platform (Twitter and Wikipedia)
mention_counts = [
    ('Twitter', df_merged_all['twitter_binary'].sum()),
    ('Wikipedia', df_merged_all['wikipedia_binary'].sum())
]

mention_df = pd.DataFrame(mention_counts, columns=['Platform', 'Mentioned Articles'])

plot_barplot(
    data=mention_df,
    x_col='Platform',
    y_col='Mentioned Articles',
    title='Number of Articles Mentioned per Platform',
    xlabel='Platform',
    ylabel='Number of Mentioned Articles',
    palette='Dark2',
    rot=0,
    distinct_colors=True
)


# Median log citation per Twitter group
twitter_stats = (
    df_merged_all.groupby('twitter_binary')['cit_log']
    .median()
    .reset_index()
    .rename(columns={'twitter_binary': 'Mentioned', 'cit_log': 'Median Log Citations'})
)
twitter_stats['Platform'] = 'Twitter'

# Median log citation per Wikipedia group
wiki_stats = (
    df_merged_all.groupby('wikipedia_binary')['cit_log']
    .median()
    .reset_index()
    .rename(columns={'wikipedia_binary': 'Mentioned', 'cit_log': 'Median Log Citations'})
)
wiki_stats['Platform'] = 'Wikipedia'

# Combine both into one dataframe
combined = pd.concat([twitter_stats, wiki_stats], ignore_index=True)

# Optional: make "Mentioned" more readable
combined['Mentioned'] = combined['Mentioned'].map({0: 'No', 1: 'Yes'})

# Plot the comparison
plot_barplot(
    data=combined,
    x_col='Mentioned',
    y_col='Median Log Citations',
    hue_col='Platform',
    title='Median Log Citation by Platform Mention',
    xlabel='Mentioned on Platform',
    ylabel='Median log(citations)',
    palette='Dark2',
    rot=0,
    format_yaxis=False
)





# Create a copy of rows with rank_flag == 1 (ranked institutions only)
df_ranked_only = df_merged_all[df_merged_all['rank_flag'] == 1].copy()


df_ranked_only.shape





# Plotting the distribution of social visibility scores for ranked institutions
plot_hist(
    df_ranked_only,
    column="stot",
    title="Distribution of Social Visibility (Ranked Institutions)",
    xlabel="Social Visibility (raw values)"
)


# Plotting the log-transformed distribution of social visibility scores for ranked institutions
plot_hist(
    df_ranked_only,
    column="stot_log1p",
    title="Log-Transformed Distribution of Social Visibility (Ranked Institutions)",
    xlabel="log(1 + Social Visibility)"
)


# Plotting the distribution of log-transformed citation counts for ranked institutions
plot_hist(
    df_ranked_only,
    column="cit_log",
    title="Distribution of Log-Transformed Citations (Ranked Institutions)",
    xlabel="log(1 + Citation Count)"
)


# Displaying basic descriptive statistics for raw citation counts author (ranked institutions only)
print("=== Descriptive Statistics: Author level Raw Citation Count (cited_by_count) ===")
print(df_ranked_only['cited_by_count'].describe())


# Plotting the log-transformed distribution of author-level citation counts for ranked institutions
plot_hist(
    data=df_ranked_only,
    column='cited_by_log1p',
    title='Distribution of Log-Transformed Author-Level Citations (Ranked Institutions)',
    xlabel='log(1 + Citation Count)'
)


# 'stot_log1p' = social visibility (log-transformed)
# 'cit_log' = citation count (log-transformed)
# Visualizing the relationship between log-transformed citation counts and social visibility among ranked institutions
plot_regplot(
    data=df_ranked_only,
    x_col="cit_log",
    y_col="stot_log1p",
    title="Relationship Between Citations and Social Visibility (Ranked Institutions)",
    xlabel="log(1 + Citation Count)",
    ylabel="log(1 + Social Visibility)",
    scatter_alpha=0.15,
    scatter_size=12,
    line_color="darkorange"
)





# Pearson (linear correlation)
pearson_ranked = df_ranked_only[['cit_log', 'stot_log1p']].corr(method='pearson')

# Spearman (rank-correlation)
spearman_ranked = df_ranked_only[['cit_log', 'stot_log1p']].corr(method='spearman')

# Print Pearson correlation with '_ranked' suffix
print("Pearson correlation (Ranked):\n", pearson_ranked.rename(columns=lambda x: x + '_ranked'))

# Print Spearman correlation with '_ranked' suffix
print("\nSpearman correlation (Ranked):\n", spearman_ranked.rename(columns=lambda x: x + '_ranked'))








# Summarizing gender-majority distribution (absolute counts and proportions) among ranked institutions
gender_counts_ranked = df_ranked_only['gender_majority'].value_counts(dropna=False)
gender_props_ranked = df_ranked_only['gender_majority'].value_counts(normalize=True, dropna=False)

gender_summary_ranked = pd.DataFrame({
    'count': gender_counts_ranked,
    'proportion': gender_props_ranked
}).sort_values(by='count', ascending=False)

print("=== Gender Majority Summary: Counts and Proportions (Ranked Institutions) ===")
print(gender_summary_ranked)


# Summarizing gender-majority distribution (counts and proportions) among ranked institutions (excluding 'undetermined' category)
df_ranked_gender_filtered = df_ranked_only[df_ranked_only['gender_majority'] != 'gender_undetermined_majority']

# Absolute counts and proportions for ranked gender data
gender_counts_ranked = df_ranked_gender_filtered['gender_majority'].value_counts(dropna=False)
gender_props_ranked = df_ranked_gender_filtered['gender_majority'].value_counts(normalize=True, dropna=False)

# Combine for easier reading
gender_summary_ranked = pd.DataFrame({
    'count': gender_counts_ranked,
    'proportion': gender_props_ranked
}).sort_values(by='count', ascending=False)

print("=== Gender Distribution Summary (Ranked Institutions, Male & Female Only) ===")
print(gender_summary_ranked)


# Plotting the gender-majority distribution among ranked institutions (excluding undetermined category)
plot_countplot(
    df_ranked_gender_filtered,
    'gender_majority',
    title="Gender Distribution (Ranked Institutions)",
    xlabel="Gender"
)


# Displaying descriptive statistics of log-transformed social visibility scores grouped by gender (ranked institutions only)
print("=== Descriptive Statistics: log(1 + Social Visibility) by Gender Majority (Ranked Institutions) ===")
gender_stats_ranked = df_ranked_gender_filtered.groupby('gender_majority')['stot_log1p'].describe()
print(gender_stats_ranked)


# Get descriptive statistics for log-transformed social visibility grouped by gender (ranked institutions only)
print("=== Descriptive Statistics: log(1 + Social Visibility) by Gender Majority (Ranked Institutions) ===")
gender_stats_ranked = df_ranked_gender_filtered.groupby('gender_majority')['stot_log1p'].describe()
display(gender_stats_ranked)


# Get descriptive statistics for stot_log1p grouped by gender for non-ranked data
gender_stats = df_gender_filtered.groupby('gender_majority')['stot_log1p'].describe()

# Get descriptive statistics for stot_log1p grouped by gender for ranked data
gender_stats_ranked = df_ranked_gender_filtered.groupby('gender_majority')['stot_log1p'].describe()

# Combine the two sets of descriptive statistics into one DataFrame for comparison
comparison_stats = pd.concat([gender_stats, gender_stats_ranked], keys=['All Institutions', 'Ranked Institutions'], axis=1)

# Print the comparison table
comparison_stats


# Comparing log-transformed social visibility across gender-majority groups among ranked institutions
plot_boxplot(
    df_ranked_gender_filtered,
    column_x='gender_majority',
    column_y='stot_log1p',
    title="Social Visibility by Gender (Ranked Institutions)",
    xlabel="Gender",
    ylabel="log(1 + Social Visibility)"
)


# === ANOVA test: stot_log1p by gender majority===

groups_ranked = [
    df_ranked_only[df_ranked_only['gender_majority'] == 'gender_male_majority']['stot_log1p'].dropna(),
    df_ranked_only[df_ranked_only['gender_majority'] == 'gender_female_majority']['stot_log1p'].dropna(),
]

f_stat, p_val = stats.f_oneway(*groups_ranked)

# Display results
print("=== ANOVA: Social Visibility by Gender Majority (Ranked Institutions) ===")
print(f"F-statistic: {f_stat:.4f}")
print(f"P-value:    {p_val:.4g}")


# === Kruskal–Wallis Test: stot_log1p by gender majority ===

male_group_ranked = df_ranked_only[df_ranked_only['gender_majority'] == 'gender_male_majority']['stot_log1p'].dropna()
female_group_ranked = df_ranked_only[df_ranked_only['gender_majority'] == 'gender_female_majority']['stot_log1p'].dropna()

kw_stat, kw_p = kruskal(female_group_ranked, male_group_ranked)

print("=== Kruskal–Wallis Test: Social Visibility by Gender Majority (Ranked Institutions) ===")
print(f"H-statistic: {kw_stat:.4f}")
print(f"P-value:     {kw_p:.5f}")


# === Dunn's post-hoc test with Bonferroni correction stot_log1p by gender majority ===

dunn_results = sp.posthoc_dunn(
    df_ranked_gender_filtered,
    val_col='stot_log1p',
    group_col='gender_majority',
    p_adjust='bonferroni'
)

print("=== Dunn's Test by Gender Majority (Ranked Institutions) ===")
print(dunn_results)


# === Linear regression model: stot_log1p ~ gender_label ===
print("=== Linear Regression: log(1 + Total Visibility) ~ Gender Majority (Ranked Institutions) ===")

model_ranked = smf.ols('stot_log1p ~ C(gender_majority)', data=df_ranked_gender_filtered).fit()

print(model_ranked.summary())





ethnicity_counts_ranked = df_ranked_only['ethnicity_majority'].value_counts()

print("=== Ethnicity categories and their frequencies (Ranked Institutions) ===")
print(ethnicity_counts_ranked)


ethnicity_props_Ranked = df_ranked_only['ethnicity_majority'].value_counts(normalize=True) * 100

ethnicity_percent_ranked = ethnicity_props_Ranked.round(2).reset_index()
ethnicity_percent_ranked.columns = ['ethnicity_majority', 'percentage']

print("=== Ethnicity Majority Group Percentages (Ranked Institutions) ===")
print(ethnicity_percent_ranked)


# Sort the full dataset by ethnicity percentage descending
ethnicity_percent = ethnicity_percent.sort_values(by='percentage', ascending=False).reset_index(drop=True)

# Sort the ranked dataset to match the same ethnicity order
ethnicity_percent_ranked = ethnicity_percent_ranked.set_index('ethnicity_majority').reindex(
    ethnicity_percent['ethnicity_majority']
).reset_index()

# Combine the two sets of descriptive statistics into one DataFrame for comparison
comparison_ethnicity = pd.concat(
    [ethnicity_percent, ethnicity_percent_ranked['percentage']],
    axis=1
)

# Rename columns for clarity
comparison_ethnicity.columns = ['ethnicity_majority', 'All Institutions (%)', 'Ranked Institutions (%)']

# Display the table
comparison_ethnicity


# Reshape the DataFrame for grouped barplot
df_long = comparison_ethnicity.melt(id_vars='ethnicity_majority',
                                     value_vars=['All Institutions (%)', 'Ranked Institutions (%)'],
                                     var_name='Institution Type',
                                     value_name='Percentage')

# Sort by 'All Institutions (%)' descending
sort_order = comparison_ethnicity.sort_values('All Institutions (%)', ascending=False)['ethnicity_majority']
df_long['ethnicity_majority'] = pd.Categorical(df_long['ethnicity_majority'], categories=sort_order, ordered=True)
df_long = df_long.sort_values('ethnicity_majority')

plot_barplot(
    data=df_long,
    x_col='ethnicity_majority',
    y_col='Percentage',
    hue_col='Institution Type',
    title='Ethnicity Majority Distribution by Institution Type',
    xlabel='Ethnicity Majority Group',
    ylabel='Percentage'
)


# List of groups: stot_log1p for each ethnicity_majority category
eth_groups_ranked = [
    df_ranked_only[df_ranked_only['ethnicity_majority'] == cat]['stot_log1p'].dropna() 
    for cat in df_ranked_only['ethnicity_majority'].unique()
]

f_stat_eth, p_val_eth = stats.f_oneway(*eth_groups_ranked)

print("=== ANOVA: Social Visibility by Ethnicity (Ranked Institutions) ===")
print(f"F-statistic: {f_stat_eth:.4f}")
print(f"P-value:    {p_val_eth:.4g}")


# Grouped list for each ethnic category
ethnicity_groups_ranked = [
    df_ranked_only[df_ranked_only['ethnicity_majority'] == eth]['stot_log1p'].dropna()
    for eth in df_ranked_only['ethnicity_majority'].unique()
]

# Kruskal–Wallis
kw_stat, kw_pval = kruskal(*ethnicity_groups_ranked)

print("=== Kruskal–Wallis Test: Social Visibility by Ethnicity (Ranked Institutions) ===")
print(f"H-statistic: {kw_stat:.4f}")
print(f"P-value:     {kw_pval:.5f}")


# Perform Dunn's test with Bonferroni correction
dunn_ethnicity_ranked = sp.posthoc_dunn(
    df_ranked_only,
    val_col='stot_log1p',
    group_col='ethnicity_majority',
    p_adjust='bonferroni'
)

# Display the p-value matrix
print("=== Dunn's Test (Ethnicity) (Ranked Institutions) ===")
print(dunn_ethnicity_ranked.round(5))


# === 4.8 Linear regression model: stot_log1p ~ ethnicity_majority ===
print("=== Linear Regression: log(1 + Total Visibility) ~ Ethnicity (Ranked Institutions) ===")

# Run OLS regression with categorical predictor
ethnicity_model_ranked = smf.ols('stot_log1p ~ C(ethnicity_majority)', data=df_ranked_only).fit()

# Display summary
print(ethnicity_model_ranked.summary())


# === Linear regression model: stot_log1p ~ ethnicity_majority on Ranked Institutions ===

# Run the regression
ethnicity_model_ranked = smf.ols('stot_log1p ~ C(ethnicity_majority)', data=df_ranked_only).fit()

# Extract coefficients and p-values
coef_ethnicity = ethnicity_model_ranked.params
pval_ethnicity = ethnicity_model_ranked.pvalues
r2_ethnicity = ethnicity_model_ranked.rsquared

# Build a clean summary DataFrame
ethnicity_regression_summary_ranked = pd.DataFrame({
    'Variable': coef_ethnicity.index,
    'Coefficient': coef_ethnicity.values,
    'P-Value': pval_ethnicity.values
})

# Add R-squared column
ethnicity_regression_summary_ranked['R-squared'] = r2_ethnicity

# Reset index for nicer view
ethnicity_regression_summary_ranked = ethnicity_regression_summary_ranked.reset_index(drop=True)

# Display nicely
print("=== Ethnicity Regression Summary (Ranked Institutions) ===")
display(ethnicity_regression_summary_ranked)





# Compute overall descriptive statistics for each platform
platform_stats_ranked = df_ranked_only[altmetric_cols].agg(['count', 'mean', 'std', 'median', 'max']).T

# Calculate percentage of articles where the platform is mentioned
platform_stats_ranked['pct_mentioned'] = (df_ranked_only[altmetric_cols] > 0).sum() / len(df_ranked_only) * 100

# Rename and round for clarity
platform_stats_ranked = platform_stats_ranked.rename(columns={'median': '50%'}).round({
    'mean': 2, 'std': 2, '50%': 0, 'max': 0, 'pct_mentioned': 2
})

# Display
print("Overall statistics for all Altmetric platforms (Ranked Institutions):")
display(platform_stats_ranked)


# Select key platforms with more than 1% of papers mentioned
key_platforms_ranked = platform_stats_ranked.index[platform_stats_ranked['pct_mentioned'] > 1].tolist()
print("\nKey platforms (>1% mentioned):", key_platforms_ranked)


# Create binary indicators for all key platforms on the full dataset
for platform in key_platforms_ranked:
    df_ranked_only[f'{platform}_binary'] = (df_ranked_only[platform] > 0).astype(int)

# Show overall usage again for all key platforms (on the full df_merged_all)
for platform in key_platforms_ranked:
    counts = df_ranked_only[f'{platform}_binary'].value_counts().sort_index()
    pct    = df_ranked_only[f'{platform}_binary'].value_counts(normalize=True).sort_index() * 100
    print(f"\n{platform.capitalize()} overall usage:")
    print(f"  Not mentioned (0): {counts[0]} ({pct[0]:.2f}%)")
    print(f"  Mentioned     (1): {counts[1]} ({pct[1]:.2f}%)")


usage_data_ranked = []

for platform in key_platforms_ranked:
    pct = df_ranked_only[f"{platform}_binary"].mean() * 100
    usage_data_ranked.append((platform.capitalize(), pct))

usage_df_ranked = (
    pd.DataFrame(usage_data_ranked, columns=['Platform', 'Mentioned (%)'])
    .sort_values('Mentioned (%)', ascending=False)
    .reset_index(drop=True)  # optional: reset index nicely
)

# Collect usage data for each platform
plot_barplot(
    data=usage_df_ranked,
    x_col='Platform',
    y_col='Mentioned (%)',
    title='Overall Platform Mention Rates (%)',
    xlabel='Platform',
    ylabel='Percentage of Articles Mentioned'
)


# Crosstab platform overlap on the full dataset
for p1, p2 in pairs:
    ct = pd.crosstab(
        df_ranked_only[f'{p1}_binary'],
        df_ranked_only[f'{p2}_binary'],
        normalize='index'
    ) * 100
    print(f"\nOverlap: {p1.capitalize()} vs {p2.capitalize()} (%)")
    print(ct.round(2))








# Convert textual rank values to numeric estimates (e.g. "=74" → 74, "301–400" → 350)
def parse_rank(rank):
    if pd.isna(rank):
        return np.nan
    if isinstance(rank, str):
        if "–" in rank:
            parts = rank.replace('–', '-').split('-')
            try:
                return (int(parts[0]) + int(parts[1])) / 2
            except:
                return np.nan
        if rank.startswith("="):
            try:
                return int(rank[1:])
            except:
                return np.nan
    try:
        return float(rank)
    except:
        return np.nan

df_ranked_only['final_rank_numeric'] = df_ranked_only['final_rank'].apply(parse_rank)


# Create rank_group from numeric values
df_ranked_only['rank_group'] = pd.cut(
    df_ranked_only['final_rank_numeric'],
    bins=[0, 50, 100, 200, 500, df_ranked_only['final_rank_numeric'].max()],
    labels=['top50', '51–100', '101–200', '201–500', '500+'],
    include_lowest=True
)

# Add '>1000' category for '1001+' values
df_ranked_only['rank_group'] = df_ranked_only['rank_group'].cat.add_categories('>1000')
df_ranked_only.loc[df_ranked_only['final_rank'] == '1001+', 'rank_group'] = '>1000'


# Define the desired order of rank groups
rank_order = ['top50', '51–100', '101–200', '201–500', '500+', '>1000']





# Calculate descriptive statistics for log-transformed social visibility by rank group
rank_group_stats = df_ranked_only.groupby('rank_group', observed=True)['stot_log1p'].describe()

# Display the table
print("=== Social Visibility (log) by Rank Group ===")
rank_group_stats


# === Average social visibility (log-transformed) by university rank group ===

# Calculate mean visibility for each rank group
rank_group_means = (
    df_ranked_only.groupby('rank_group', observed=True)['stot_log1p']
    .mean()
    .round(2)
    .reset_index()
    .rename(columns={'stot_log1p': 'Mean_log_Visibility'})
    .sort_values('rank_group')  # Ensure proper rank group ordering
)

# Plot using the custom barplot function
plot_barplot(
    data=rank_group_means,
    x_col='rank_group',
    y_col='Mean_log_Visibility',
    title='Average Social Visibility (log) by University Rank Group',
    xlabel='University Rank Group',
    ylabel='Mean log(1 + Total Visibility)',
    format_yaxis=False
)


# === Average citation count (log-transformed) by university rank group ===

# Calculate mean log citation count for each rank group
rank_group_cit_means = (
    df_ranked_only
    .groupby('rank_group', observed=True)['cit_log']
    .mean()
    .reset_index()
    .rename(columns={'cit_log': 'Mean_log_Citations'})
    .sort_values('rank_group')  # Ensure proper ordering of rank groups
)

# Plot using the custom barplot function
plot_barplot(
    data=rank_group_cit_means,
    x_col='rank_group',
    y_col='Mean_log_Citations',
    title='Average Citation Count (log) by University Rank Group',
    xlabel='University Rank Group',
    ylabel='Mean log(1 + Citation Count)',
    format_yaxis=False
)


# === Average raw citation count by university rank group ===

# Calculate mean raw citation count for each rank group
rank_group_allcit_means = (
    df_ranked_only
    .groupby('rank_group', observed=True)['all_citaitons']
    .mean()
    .reset_index()
    .rename(columns={'all_citaitons': 'Mean_Citations'})
    .sort_values('rank_group')  # Ensure proper ordering of rank groups
)

# Plot using the custom barplot function
plot_barplot(
    data=rank_group_allcit_means,
    x_col='rank_group',
    y_col='Mean_Citations',
    title='Average Citation Count by University Rank Group',
    xlabel='University Rank Group',
    ylabel='Mean Citation Count'
)


# === Descriptive statistics for cited_by_count by rank group (Ranked Institutions) ===

# Calculate descriptive stats for raw citation counts within each rank group
rank_group_cite_stats = (
    df_ranked_only
    .groupby('rank_group', observed=True)['cited_by_count']
    .describe()
)

# Display the table
print("=== Citation Counts by University Rank Group ===")
rank_group_cite_stats


# === Average raw citation count by university rank group ===

# Calculate mean cited_by_count for each rank group
rank_group_cited_means = (
    df_ranked_only
    .groupby('rank_group', observed=True)['cited_by_count']
    .mean()
    .reset_index()
    .rename(columns={'cited_by_count': 'Mean_Citations'})
    .sort_values('rank_group')  # Ensure proper ordering
)

# Plot using the custom barplot function
plot_barplot(
    data=rank_group_cited_means,
    x_col='rank_group',
    y_col='Mean_Citations',
    title='Average Citation Count by University Rank Group',
    xlabel='University Rank Group',
    ylabel='Mean Citation Count'
)


# === 3. (Optional) Barplot: average log-citations by rank group ===
rank_group_citlog_means = (
    df_ranked_only
    .groupby('rank_group', observed=True)['cited_by_log1p']
    .mean()
    .reset_index()
    .rename(columns={'cited_by_log1p': 'Mean_log_Citations'})
    .sort_values('rank_group')
)

plot_barplot(
    data=rank_group_citlog_means,
    x_col='rank_group',
    y_col='Mean_log_Citations',
    title='Average log(1 + Citations) by University Rank Group',
    xlabel='University Rank Group',
    ylabel='Mean log(1 + Citation Count)'
)





# === Correlations by rank group, silencing the warning ===

def compute_corr(subdf):
    return pd.Series({
        'pearson': subdf['cit_log'].corr(subdf['stot_log1p'], method='pearson'),
        'spearman': subdf['cit_log'].corr(subdf['stot_log1p'], method='spearman')
    })

corr_by_rank = (
    df_ranked_only
    .groupby('rank_group', observed=True)
    .apply(compute_corr, include_groups=False)  # <-- ide tesszük
    .round(3)
)

print("=== Correlations by University Rank Group ===")
corr_by_rank


# Copy the original rank value to preserve it
df_ranked_only['final_rank_numeric'] = pd.to_numeric(
    df_ranked_only['final_rank'], errors='coerce'
)

# Assign 1001 to those explicitly marked as '1001+'
df_ranked_only.loc[df_ranked_only['final_rank'] == '1001+', 'final_rank_numeric'] = 1001


# Keep only rows with valid rank and visibility
rank_numeric_df = df_ranked_only.dropna(subset=['final_rank_numeric', 'stot_log1p']).copy()

# Define threshold: pl. top 1% visibility
threshold = rank_numeric_df['stot_log1p'].quantile(0.99)

# Find outliers with low-ranked institutions but very high visibility
outlier_df = rank_numeric_df[
    (rank_numeric_df['stot_log1p'] >= threshold) &
    (rank_numeric_df['final_rank_numeric'] > 1000)  # low prestige group
]

# Display results
print("=== Outliers: High Visibility from Low-Ranked Institutions ===")
print(outlier_df[['final_rank', 'final_rank_numeric', 'stot_log1p', 'doi']].sort_values(by='stot_log1p', ascending=False))


# Visualizing the relationship between university rank and log-transformed social visibility
plot_regplot(
    data=rank_numeric_df,
    x_col='final_rank_numeric',
    y_col='stot_log1p',
    title='Social Visibility vs. University Rank (Numeric)',
    xlabel='University Rank (lower is better)',
    ylabel='log(1 + Social Visibility)',
    scatter_alpha=0.05,
    scatter_size=10
)


# Visualizing the relationship between university rank groups, article output, and mean social visibility
# (Bar = number of articles, Line = average log-transformed social visibility)
# Step 1: compute group counts and mean social visibility
rank_stats = (
    df_ranked_only
    .groupby('rank_group', observed=True)['stot_log1p']
    .agg(['count', 'mean'])
    .reindex(rank_order)
    .reset_index()
    .rename(columns={'mean': 'Mean_Social_Visibility', 'count': 'Article_Count'})
)

# Step 2: plot combined bar and line chart
combined_bar_line_plot(
    data=rank_stats,
    x_col='rank_group',
    bar_y_col='Article_Count',
    line_y_col='Mean_Social_Visibility',
    title='Article Volume and Mean Social Visibility by University Rank',
    xlabel='University Rank Group',
    bar_ylabel='Number of Articles',
    line_ylabel='Mean log(1 + Social Visibility)',
    palette='Dark2',
    line_color='orange'
)


# === ANOVA: Social visibility by rank group ===
from scipy import stats
# Create list of stot_log1p values for each rank group
groups_by_rank = [
    df_ranked_only[df_ranked_only['rank_group'] == group]['stot_log1p'].dropna()
    for group in rank_order
]

# Perform one-way ANOVA
f_stat, p_val = stats.f_oneway(*groups_by_rank)

# Display results
print("=== ANOVA: Social Visibility by University Rank Group ===")
print(f"F-statistic: {f_stat:.4f}")
print(f"P-value:    {p_val:.4g}")


# === Kruskal–Wallis Test: Social visibility by rank group ===

# Extract groups again for clarity
rank_groups_individual = [
    df_ranked_only[df_ranked_only['rank_group'] == group]['stot_log1p'].dropna()
    for group in rank_order
]

# Run the Kruskal–Wallis test
kw_stat, kw_p = kruskal(*rank_groups_individual)

# Display results
print("=== Kruskal–Wallis Test: Social Visibility by University Rank Group ===")
print(f"H-statistic: {kw_stat:.4f}")
print(f"P-value:     {kw_p:.5f}")


# === Dunn's post-hoc test with Bonferroni correction ===

# Perform pairwise comparisons
dunn_results_rank = sp.posthoc_dunn(
    df_ranked_only,
    val_col='stot_log1p',
    group_col='rank_group',
    p_adjust='bonferroni'
)

# Display Dunn test result matrix
print("=== Dunn's Test: Social Visibility by University Rank Group ===")
display(dunn_results_rank)


# === Linear regression: stot_log1p ~ rank_group ===

# Fit OLS regression model
model_rankgroup = smf.ols('stot_log1p ~ C(rank_group)', data=df_ranked_only).fit()

# Print regression summary
print("=== OLS Regression: Social Visibility ~ Rank Group ===")
print(model_rankgroup.summary())


# Grouped by DOI by stot_log1p 
outlier_summary = (
    outlier_df
    .groupby('doi')
    .agg({
        'stot_log1p': 'first',
        'final_rank': 'first',
        'final_rank_numeric': 'first'
    })
    .sort_values('stot_log1p', ascending=False)
)

print(outlier_summary)


#outlier_summary.to_csv('manual_review/outlier_high_visibility_low_rank.csv')


import matplotlib.pyplot as plt
import seaborn as sns
from matplotlib.lines import Line2D


# === Swarmplot of social visibility by rank group, with outliers and clean legend ===

# Sample a subset for the swarmplot
sampled_df = rank_numeric_df.sample(3000, random_state=42)

plt.figure(figsize=(10, 6))

# Base swarmplot
sns.swarmplot(
    data=sampled_df,
    x='rank_group',
    y='stot_log1p',
    order=rank_order,
    size=4,
    alpha=0.7
)

# Outliers in red (without duplicate legend entries)
sns.stripplot(
    data=outlier_df,
    x='rank_group',
    y='stot_log1p',
    order=rank_order,
    color='red',
    size=7,
    jitter=True,
    label=None
)

# Add custom circular dot to legend
outlier_dot = Line2D([0], [0], marker='o', color='w', label='Outliers',
                     markerfacecolor='red', markersize=8)
plt.legend(handles=[outlier_dot])

plt.title("Swarmplot of Social Visibility by Rank Group (with Outliers)")
plt.xlabel("Rank Group")
plt.ylabel("log(1 + Social Visibility)")
plt.tight_layout()

# Save the figure using your automated naming system
save_current_figure()

plt.show()








# Recreate the filtered dataset, keeping all columns including 'rank_group'
df_ranked_gender_filtered = df_ranked_only[df_ranked_only['gender_majority'] != 'gender_undetermined_majority'].copy()

# Convert 'rank_group' to a categorical variable with specified order
df_ranked_gender_filtered['rank_group'] = pd.Categorical(
    df_ranked_gender_filtered['rank_group'],
    categories=rank_order,
    ordered=True
)

# Now group by rank_group and gender_label
gender_by_rankgroup_counts = (
    df_ranked_gender_filtered
    .groupby(['rank_group', 'gender_majority'], observed=True)
    .size()
    .unstack(fill_value=0)
)
# Display results
print("=== Gender Majority Counts by Rank Group ===")
gender_by_rankgroup_counts


# Calculate proportions (row-wise, by rank group)
gender_by_rankgroup_props = gender_by_rankgroup_counts.div(gender_by_rankgroup_counts.sum(axis=1), axis=0)

print("\n=== Gender Proportions by Rank Group ===")
gender_by_rankgroup_props


# Melt the proportion DataFrame into long format for plotting
gender_by_rankgroup_props_melted = (
    gender_by_rankgroup_props
    .reset_index()
    .melt(id_vars='rank_group', var_name='Gender', value_name='Proportion')
)

# Clean up labels
gender_by_rankgroup_props_melted['Gender'] = gender_by_rankgroup_props_melted['Gender'].map({
    'gender_male_majority': 'Male',
    'gender_female_majority': 'Female'
})

# Round proportions for nicer y-axis
gender_by_rankgroup_props_melted['Proportion'] = gender_by_rankgroup_props_melted['Proportion'].round(2)

# Plot
plot_barplot(
    data=gender_by_rankgroup_props_melted,
    x_col='rank_group',
    y_col='Proportion',
    hue_col='Gender',
    title='Gender Distribution by University Rank Group',
    xlabel='University Rank Group',
    ylabel='Proportion',
    format_yaxis=False  # prevent integer-only formatting on 0-1 values
)


# === Descriptive statistics for log-transformed social visibility by gender and university rank group ===
gender_rankgroup_stats = (
    df_ranked_gender_filtered
    .groupby(['rank_group', 'gender_majority'], observed=True)['stot_log1p']
    .describe()
    .round(3)
)

print("=== Descriptive Statistics: log(1 + Social Visibility) by Gender and Rank Group ===")
gender_rankgroup_stats


# === Combined boxplot of social visibility by rank group and gender ===
plt.figure(figsize=(10, 6))

sns.boxplot(
    data=df_ranked_gender_filtered,
    x='rank_group',
    y='stot_log1p',
    hue='gender_majority',
    palette='Dark2'
)

# Titles and labels
plt.title("Social Visibility by Rank Group and Gender (Ranked Institutions)")
plt.xlabel("University Rank Group")
plt.ylabel("log(1 + Social Visibility)")

# Display the legend outside the plot
plt.legend(title="Gender", bbox_to_anchor=(1.05, 1), loc='upper left')

plt.tight_layout()
plt.show()


# === One-way ANOVA: Testing for gender-based differences in social visibility within each university rank group ===
for group in rank_order:
    subdf = df_ranked_gender_filtered[df_ranked_gender_filtered['rank_group'] == group]
    
    # Create list of stot_log1p values grouped by gender
    groups = [subdf[subdf['gender_majority'] == g]['stot_log1p'].dropna() for g in subdf['gender_majority'].unique()]
    
    # Run ANOVA
    f_stat, p_val = stats.f_oneway(*groups)
    print(f"=== ANOVA: Social Visibility by Gender Majority (Rank Group: {group}) ===")
    print(f"F-statistic: {f_stat:.4f} | P-value: {p_val:.4g}\n")


# Kruskal–Wallis test by gender within each rank group
for group in rank_order:
    subdf = df_ranked_gender_filtered[df_ranked_gender_filtered['rank_group'] == group]
    
    # Create list of stot_log1p values by gender
    groups = [subdf[subdf['gender_majority'] == g]['stot_log1p'].dropna() for g in subdf['gender_majority'].unique()]
    
    # Run Kruskal–Wallis test
    h_stat, p_val = stats.kruskal(*groups)
    print(f"=== Kruskal–Wallis Test: Social Visibility by Gender Majority (Rank Group: {group}) ===")
    print(f"H-statistic: {h_stat:.4f} | P-value: {p_val:.4g}\n")


# Initialize list to collect the results
anova_kruskal_results = []

# Loop through each rank group
for group in rank_order:
    subset = df_ranked_gender_filtered[df_ranked_gender_filtered['rank_group'] == group]
    
    # Extract the groups
    groups = [subset[subset['gender_majority'] == gender]['stot_log1p'].dropna() for gender in ['gender_female_majority', 'gender_male_majority']]
    
    # Perform ANOVA
    f_stat, f_pval = stats.f_oneway(*groups)
    
    # Perform Kruskal–Wallis test
    h_stat, h_pval = stats.kruskal(*groups)
    
    # Store the results
    anova_kruskal_results.append({
        'Rank Group': group,
        'ANOVA F-statistic': round(f_stat, 4),
        'ANOVA p-value': round(f_pval, 4),
        'Kruskal H-statistic': round(h_stat, 4),
        'Kruskal p-value': round(h_pval, 4)
    })

# Create DataFrame from the results
anova_kruskal_df = pd.DataFrame(anova_kruskal_results)

# Display the summary table
print("=== ANOVA and Kruskal–Wallis Test Results by Rank Group ===")
display(anova_kruskal_df)


# Dunn's post-hoc test (overall gender comparison)
print("=== Dunn Test Results by Rank Group ===")
for group in rank_order:
    subdf = df_ranked_gender_filtered[df_ranked_gender_filtered['rank_group'] == group]
    if subdf.empty:
        continue

    dunn_result = sp.posthoc_dunn(
        subdf,
        val_col='stot_log1p',
        group_col='gender_majority',
        p_adjust='bonferroni'
    )

    print(f"=== Dunn's Test by Gender (Rank Group: {group}) ===")
    print(dunn_result.round(5))
    print("\n")


for group in rank_order:
    # Filter the data for the current rank group
    subdf = df_ranked_gender_filtered[df_ranked_gender_filtered['rank_group'] == group]
    
    if subdf.empty:
        continue  # Skip if no data for this group

    # Fit the OLS model: stot_log1p ~ gender_label
    model = smf.ols('stot_log1p ~ C(gender_majority)', data=subdf).fit()
    
    # Print a summary header
    print(f"=== Linear Regression (Gender Effect) for Rank Group: {group} ===")
    print(model.summary())
    print("\n")


# Create a list to collect results
regression_results = []

# Loop over each rank group
for group in rank_order:
    subdf = df_ranked_gender_filtered[df_ranked_gender_filtered['rank_group'] == group]
    if subdf.empty:
        continue

    # Fit the OLS model
    model = smf.ols('stot_log1p ~ C(gender_majority)', data=subdf).fit()

    # Extract the needed values
    coef_male = model.params.get('C(gender_majority)[T.gender_male_majority]', float('nan'))
    pval_male = model.pvalues.get('C(gender_majority)[T.gender_male_majority]', float('nan'))
    r_squared = model.rsquared

    # Save the results
    regression_results.append({
        'Rank Group': group,
        'Coef (Male)': coef_male,
        'P-Value (Male)': pval_male,
        'R-squared': r_squared
    })

# Create a DataFrame from the results
regression_summary = pd.DataFrame(regression_results)

# Round values nicely
regression_summary = regression_summary.round({
    'Coef (Male)': 4,
    'P-Value (Male)': 4,
    'R-squared': 4
})

# Display
regression_summary





# === Count ethnicity_majority frequencies within each rank group ===

# Group by rank_group and ethnicity_majority, then count
ethnicity_by_rankgroup_counts = (
    df_ranked_only
    .groupby(['rank_group', 'ethnicity_majority'], observed=True)
    .size()
    .unstack(fill_value=0)
)

# Display the table
print("=== Ethnicity categories and their frequencies by Rank Group ===")
ethnicity_by_rankgroup_counts


# === Compute ethnicity proportions (%) within each rank group ===

# Group by rank_group and ethnicity_majority, then count
ethnicity_by_rankgroup_counts = (
    df_ranked_only
    .groupby(['rank_group', 'ethnicity_majority'], observed=True)
    .size()
    .unstack(fill_value=0)
)

# Calculate proportions within each rank group
ethnicity_by_rankgroup_props = ethnicity_by_rankgroup_counts.div(ethnicity_by_rankgroup_counts.sum(axis=1), axis=0) * 100

# Round the results for easier reading
ethnicity_by_rankgroup_props = ethnicity_by_rankgroup_props.round(2)

# Display the proportion table
print("=== Ethnicity Majority Group Proportions (%) by Rank Group ===")
ethnicity_by_rankgroup_props


# === Descriptive statistics for social visibility (stot_log1p) grouped by ethnicity and rank group ===

# Group by rank_group and ethnicity_majority, and compute count, mean, std
ethnicity_visibility_ranked = (
    df_ranked_only
    .groupby(['rank_group', 'ethnicity_majority'], observed=True)['stot_log1p']
    .agg(['count', 'mean', 'std'])
    .round(3)
)

# Display the result sorted by mean visibility within each rank group
print("=== Social Visibility (log) by Ethnicity and Rank Group ===")
print (ethnicity_visibility_ranked)


# === ANOVA: Social Visibility by Ethnicity within each Rank Group ===
# Loop through each rank group
for group in rank_order:
    # Subset the ranked data for this group
    subdf = df_ranked_only[df_ranked_only['rank_group'] == group]
    
    # Skip if no data
    if subdf.empty:
        continue

    # Build a list of stot_log1p arrays, one per ethnicity category in this group
    eth_groups = [
        subdf[subdf['ethnicity_majority'] == cat]['stot_log1p'].dropna()
        for cat in subdf['ethnicity_majority'].unique()
    ]
    
    # Run one‐way ANOVA
    f_stat, p_val = stats.f_oneway(*eth_groups)
    
    # Print the results for this rank group
    print(f"=== ANOVA: Social Visibility by Ethnicity (Rank Group: {group}) ===")
    print(f"F-statistic: {f_stat:.4f}")
    print(f"P-value:     {p_val:.4g}\n")


# === Kruskal–Wallis Test: Social Visibility by Ethnicity within each Rank Group ===
# Loop over each rank group
for group in rank_order:
    # Subset the data to the current rank group
    subdf = df_ranked_only[df_ranked_only['rank_group'] == group]
    if subdf.empty:
        continue  # skip groups with no data

    # Build a list of arrays of stot_log1p, one for each ethnicity_majority in this group
    eth_groups = [
        subdf[subdf['ethnicity_majority'] == eth]['stot_log1p'].dropna()
        for eth in subdf['ethnicity_majority'].unique()
    ]

    # Run the Kruskal–Wallis test
    h_stat, p_val = stats.kruskal(*eth_groups)

    # Print the results
    print(f"=== Kruskal–Wallis: Social Visibility by Ethnicity (Rank Group: {group}) ===")
    print(f"H-statistic: {h_stat:.4f}")
    print(f"P-value:     {p_val:.4g}\n")


# === 3.7 Combined ANOVA & Kruskal–Wallis Test Results for Ethnicity by Rank Group ===
# Initialize list to collect the results
anova_kruskal_eth_results = []

# Loop through each rank group
for group in rank_order:
    subdf = df_ranked_only[df_ranked_only['rank_group'] == group]
    if subdf.empty:
        continue  # skip if no data in this group

    # Build a list of stot_log1p arrays, one per ethnicity category
    eth_categories = subdf['ethnicity_majority'].unique()
    eth_groups = [
        subdf[subdf['ethnicity_majority'] == cat]['stot_log1p'].dropna()
        for cat in eth_categories
    ]
    
    # Perform one‐way ANOVA
    f_stat, f_pval = stats.f_oneway(*eth_groups)
    
    # Perform Kruskal–Wallis test
    h_stat, h_pval = stats.kruskal(*eth_groups)
    
    # Store the results
    anova_kruskal_eth_results.append({
        'Rank Group': group,
        'ANOVA F-statistic': round(f_stat, 4),
        'ANOVA p-value':     round(f_pval, 4),
        'Kruskal H-statistic': round(h_stat, 4),
        'Kruskal p-value':     round(h_pval, 4)
    })

# Create a DataFrame from the results
anova_kruskal_eth_df = pd.DataFrame(anova_kruskal_eth_results)

# Display the summary table
print("=== ANOVA and Kruskal–Wallis Test Results Social Visibility by Ethnicity by Rank Group (Ethnicity) ===")
display(anova_kruskal_eth_df)


# === Dunn's post-hoc test by Ethnicity within each Rank Group ===
# Loop through each rank group
for group in rank_order:
    subdf = df_ranked_only[df_ranked_only['rank_group'] == group]
    if subdf.empty:
        continue

    # Perform Dunn's test on stot_log1p across ethnicity_majority categories
    dunn_result = sp.posthoc_dunn(
        subdf,
        val_col='stot_log1p',
        group_col='ethnicity_majority',
        p_adjust='bonferroni'
    )

    # Print the results for this rank group
    print(f"=== Dunn's Test by Ethnicity (Rank Group: {group}) ===")
    print(dunn_result.round(5))
    print("\n")


# === Linear Regression: stot_log1p ~ ethnicity_majority by Rank Group ===

# Loop through each rank group in the desired order
for group in rank_order:
    # Filter the data for the current rank group
    subdf = df_ranked_only[df_ranked_only['rank_group'] == group]
    
    # Skip if there is no data in this group
    if subdf.empty:
        continue

    # Fit the OLS model: stot_log1p ~ ethnicity_majority
    model_eth = smf.ols('stot_log1p ~ C(ethnicity_majority)', data=subdf).fit()
    
    # Print a header and the summary
    print(f"=== Linear Regression (Ethnicity Effect) for Rank Group: {group} ===")
    print(model_eth.summary())
    print("\n")


# === 3.9 Linear Regression Summary by Ethnicity and Rank Group ===
# List to collect results
ethnicity_regression_results = []

# Loop over each rank group
for group in rank_order:
    subdf = df_ranked_only[df_ranked_only['rank_group'] == group]
    if subdf.empty:
        continue

    # Fit the OLS model for ethnicity effect
    model = smf.ols('stot_log1p ~ C(ethnicity_majority)', data=subdf).fit()

    # Prepare result dict with R-squared
    result = {'Rank Group': group, 'R-squared': model.rsquared}

    # Extract coefficients and p-values for each ethnicity category (excluding intercept)
    for var, coef in model.params.items():
        if var == 'Intercept':
            continue
        pval = model.pvalues[var]
        # Clean variable name for column header
        var_name = var.replace('C(ethnicity_majority)[T.', '').rstrip(']')
        result[f'Coef ({var_name})']    = round(coef, 4)
        result[f'P-Value ({var_name})'] = round(pval, 4)

    ethnicity_regression_results.append(result)

# Convert to DataFrame and order columns
ethnicity_regression_summary = pd.DataFrame(ethnicity_regression_results)

# Display summary
print("=== Ethnicity Regression Summary by Rank Group ===")
display(ethnicity_regression_summary)





# === Descriptive statistics for Altmetric platforms by Rank Group ===

# List to collect all stats
platform_stats_by_rank = []

# Loop through each rank group
for group in rank_order:
    subdf = df_ranked_only[df_ranked_only['rank_group'] == group]
    total_n = len(subdf)
    if total_n == 0:
        continue

    # Compute stats for each platform column
    for platform in altmetric_cols:
        series = subdf[platform]
        agg_stats = series.agg(['count', 'mean', 'std', 'median', 'max'])
        pct_mentioned = (series > 0).sum() / total_n * 100

        platform_stats_by_rank.append({
            'Rank Group':      group,
            'Platform':        platform,
            'count':           agg_stats['count'],
            'mean':            agg_stats['mean'],
            'std':             agg_stats['std'],
            '50%':             agg_stats['median'],
            'max':             agg_stats['max'],
            'pct_mentioned':   pct_mentioned
        })

# Create DataFrame
platform_stats_rg_df = pd.DataFrame(platform_stats_by_rank)

# Round numeric columns for clarity
platform_stats_rg_df = platform_stats_rg_df.round({
    'mean': 2,
    'std': 2,
    '50%': 0,
    'max': 0,
    'pct_mentioned': 2
})

# Set multi‐index for easier pivoting or display
platform_stats_rg_df = platform_stats_rg_df.set_index(['Rank Group', 'Platform'])

# Display the table
print("=== Platform Descriptive Statistics by Rank Group ===")
display(platform_stats_rg_df)


# Reset the index so we can filter by “Platform”
stats = platform_stats_rg_df.reset_index().rename(
    columns={'level_0': 'Rank Group', 'level_1': 'Platform'}
)

# Ensure your rank groups are in the desired order
rank_order = ['top50', '51–100', '101–200', '201–500', '500+', '>1000']

for rg in rank_order:
    # select only this rank group & only key platforms
    sub = (
        stats
        .loc[
            (stats['Rank Group'] == rg) &
            (stats['Platform'].isin(key_platforms_ranked))
        ]
        .set_index('Platform')
        [['count', 'mean', 'std', '50%', 'max', 'pct_mentioned']]
    )
    if sub.empty:
        continue
    
    print(f"\n=== Rank Group: {rg} (Key Platforms) ===")
    display(sub)


# === Platform mention counts (0 vs. 1) by University Rank Group ===
# Note: 0 = Not mentioned, 1 = Mentioned

# List of binary platform columns
binary_cols = [f"{p}_binary" for p in key_platforms_ranked]

# Melt to long format
melted = df_ranked_only.melt(
    id_vars='rank_group',
    value_vars=binary_cols,
    var_name='Platform',
    value_name='Mentioned'
)

# Clean up platform names
melted['Platform'] = (
    melted['Platform']
      .str.replace('_binary', '', regex=False)
      .str.capitalize()
)

# Compute counts of 0 vs. 1 per rank_group and platform
mention_counts = (
    melted
      .groupby(['rank_group', 'Platform', 'Mentioned'])
      .size()
      .unstack(fill_value=0)
      .rename(columns={0: 'Not mentioned', 
                       1: 'Mentioned'})
)

print("=== Platform Mention Counts by University Rank Group ===")
display(mention_counts)


# === Platform mention rates (%) by University Rank Group (no plot) ===

# List of binary columns for key platforms
binary_cols = [f"{p}_binary" for p in key_platforms_ranked]

# Compute percentage mentioned per rank_group
mention_rates = (
    df_ranked_only
      .groupby('rank_group', observed=True)[binary_cols]
      .mean()            # fraction of 1’s
      .mul(100)          # → percentage
      .round(2)          # two decimal places
)

# Rename columns for readability
mention_rates = mention_rates.rename(
    columns={f'{p}_binary': p.capitalize() for p in key_platforms_ranked}
)

print("=== Platform Mention Rates (%) by University Rank Group ===")
display(mention_rates)


# === 7.1 Platform mention rates (%) by Rank Group and Platform (key platforms) ===

# Prepare a list to collect results
usage_by_group = []

# Loop over each rank group in the desired order
for group in rank_order:
    subdf = df_ranked_only[df_ranked_only['rank_group'] == group]
    if subdf.empty:
        continue
    n = len(subdf)
    # For each key platform, compute pct mentioned in this group
    for platform in key_platforms_ranked:
        pct = subdf[f'{platform}_binary'].mean() * 100
        usage_by_group.append((group, platform.capitalize(), round(pct, 2)))

# Convert to DataFrame
usage_df_by_group = pd.DataFrame(
    usage_by_group,
    columns=['Rank Group', 'Platform', 'Mentioned (%)']
)

# Optionally pivot for wide format
usage_pivot = usage_df_by_group.pivot(
    index='Rank Group', columns='Platform', values='Mentioned (%)'
)

plot_barplot(
    data=usage_df_by_group,
    x_col='Rank Group',
    y_col='Mentioned (%)',
    hue_col='Platform',
    title='Platform Mention Rates by University Rank Group',
    xlabel='University Rank Group',
    ylabel='Percentage of Articles Mentioned'
)


# === Average Social Visibility by Rank Group and Platform ===
# Computing average log-transformed social visibility for mentioned articles across university rank groups and platforms

# List of key platforms to include
key_platforms = ['twitter', 'facebook', 'news', 'blogs', 'reddit']

# Compute mean log-visibility for each (rank_group, platform)
vis_by_rank_platform = (
    df_ranked_only
    .loc[:, ['rank_group', 'stot_log1p'] + key_platforms]
    .melt(id_vars=['rank_group', 'stot_log1p'], 
          value_vars=key_platforms,
          var_name='Platform',
          value_name='Mentioned')
    # keep only rows where the platform is actually mentioned (binary > 0)
    .query('Mentioned > 0')
    .groupby(['rank_group', 'Platform'], observed=True)['stot_log1p']
    .mean()
    .reset_index()
    .rename(columns={'stot_log1p': 'Mean_log_Visibility'})
    # ensure the rank groups appear in the desired order
    .assign(rank_group=lambda d: pd.Categorical(
        d['rank_group'],
        categories=['top50','51–100','101–200','201–500','500+','>1000'],
        ordered=True
    ))
    .sort_values(['rank_group','Platform'])
)

# Plot with our custom barplot (distinct colors per platform)
plot_barplot(
    data=vis_by_rank_platform,
    x_col='rank_group',
    y_col='Mean_log_Visibility',
    hue_col='Platform',
    title='Average Social Visibility (log) by Rank Group and Platform',
    xlabel='University Rank Group',
    ylabel='Mean log(1 + Social Visibility)',
    palette='Dark2',
    rot=45,
    format_yaxis=False
)








# === Grouped Descriptive Statistics ===
group_columns = ['gender_majority', 'ethnicity_majority', 'rank_group']

descriptive_tables = {}

for group_col in group_columns:
    if group_col == 'gender_majority':
        subdf = df_ranked_only[df_ranked_only['gender_majority'] != 'gender_undetermined_majority']
    else:
        subdf = df_ranked_only

    desc_stats = (
        subdf
        .groupby(group_col, observed=True) 
        .agg(
            Mean_Social_Visibility=('stot_log1p', 'mean'),
            Std_Social_Visibility=('stot_log1p', 'std'),
            Mean_Citation=('cit_log', 'mean'),
            Std_Citation=('cit_log', 'std')
        )
        .round(3)  # Round for neatness
        .sort_values('Mean_Social_Visibility', ascending=False) 
    )
    
    descriptive_tables[group_col] = desc_stats

# Each result individually:
print("=== Descriptive Statistics by Gender (Social Visibility and Citation) ===")
display(descriptive_tables['gender_majority'])

print("\n=== Descriptive Statistics by Ethnicity (Social Visibility and Citation) ===")
display(descriptive_tables['ethnicity_majority'])

print("\n=== Descriptive Statistics by Rank Group (Social Visibility and Citation) ===")
display(descriptive_tables['rank_group'])


# === Combined Barplot for Social Visibility and Citations by Gender (excluding unknown) ===

# Filter out 'unknown' gender
gender_filtered_df = descriptive_tables['gender_majority'].drop(index='gender_undetermined_majority', errors='ignore')

# Prepare data
combined_df = gender_filtered_df[['Mean_Social_Visibility', 'Mean_Citation']].reset_index()

# Melt into long format
combined_long = combined_df.melt(id_vars='gender_majority',
                                 value_vars=['Mean_Social_Visibility', 'Mean_Citation'],
                                 var_name='Metric',
                                 value_name='Mean_Value')

# Rename metrics
combined_long['Metric'] = combined_long['Metric'].map({
    'Mean_Social_Visibility': 'Social Visibility (log)',
    'Mean_Citation': 'Citations (log)'
})

# Plot
plt.figure(figsize=(8, 6))
ax = sns.barplot(
    data=combined_long,
    x='gender_majority',
    y='Mean_Value',
    hue='Metric',
    palette='Dark2'
)

plt.title('Average Social Visibility and Citations by Gender Majority')
plt.xlabel('Gender Majority')
plt.ylabel('Mean log(1 + Value)')
plt.xticks(rotation=0)
ymax = combined_long['Mean_Value'].max() * 1.13
ax.set_ylim(0, ymax)
ax.legend(title="Metric",
          loc='upper right',     
          frameon=True)           

plt.tight_layout()
save_current_figure()
plt.show()


# === Combined Barplot for Social Visibility and Citations by Ethnicity ===

# Prepare data
combined_df = descriptive_tables['ethnicity_majority'][['Mean_Social_Visibility', 'Mean_Citation']].reset_index()

# Melt into long format
combined_long = combined_df.melt(id_vars='ethnicity_majority',
                                 value_vars=['Mean_Social_Visibility', 'Mean_Citation'],
                                 var_name='Metric',
                                 value_name='Mean_Value')

# Rename metrics
combined_long['Metric'] = combined_long['Metric'].map({
    'Mean_Social_Visibility': 'Social Visibility (log)',
    'Mean_Citation': 'Citations (log)'
})

# Plot
plt.figure(figsize=(12, 7))
sns.barplot(
    data=combined_long,
    x='ethnicity_majority',
    y='Mean_Value',
    hue='Metric',
    palette='Dark2'
)

plt.title('Average Social Visibility and Citations by Ethnicity Majority')
plt.xlabel('Ethnicity Majority Group')
plt.ylabel('Mean log(1 + Value)')
plt.xticks(rotation=45, ha="right")
plt.legend(title="Metric")
plt.tight_layout()
save_current_figure()
plt.show()


# === Combined Barplot for Social Visibility and Citations by Rank Group ===

# Prepare data
combined_df = descriptive_tables['rank_group'][['Mean_Social_Visibility', 'Mean_Citation']].reset_index()

# Melt into long format
combined_long = combined_df.melt(id_vars='rank_group',
                                 value_vars=['Mean_Social_Visibility', 'Mean_Citation'],
                                 var_name='Metric',
                                 value_name='Mean_Value')

# Rename metrics for nicer labels
combined_long['Metric'] = combined_long['Metric'].map({
    'Mean_Social_Visibility': 'Social Visibility (log)',
    'Mean_Citation': 'Citations (log)'
})

# Plot
plt.figure(figsize=(10, 6))
sns.barplot(
    data=combined_long,
    x='rank_group',
    y='Mean_Value',
    hue='Metric',
    palette='Dark2'
)

plt.title('Average Social Visibility and Citations by University Rank Group')
plt.xlabel('University Rank Group')
plt.ylabel('Mean log(1 + Value)')
plt.xticks(rotation=45)
plt.legend(title="Metric")
plt.tight_layout()
save_current_figure()
plt.show()





# === Regression Summary for Group Effects on Visibility and Citations ===

# Initialize list to collect all results
regression_results = []

# Define grouping variables to test
grouping_vars = ['gender_majority', 'ethnicity_majority', 'rank_group']

# Loop over grouping variables
for group_var in grouping_vars:
    # Filter out 'unknown' gender if needed
    if group_var == 'gender_majority':
        data = df_ranked_only[df_ranked_only['gender_majority'] != 'gender_undetermined_majority']
    else:
        data = df_ranked_only

    # --- Regression 1: Social Visibility ---
    model_visibility = smf.ols(f'stot_log1p ~ C({group_var})', data=data).fit()

    # --- Regression 2: Citation Counts ---
    model_citation = smf.ols(f'cit_log ~ C({group_var})', data=data).fit()

    # Store results
    result = {
        'Grouping Variable': group_var,
        'Visibility R-squared': round(model_visibility.rsquared, 4),
        'Citation R-squared': round(model_citation.rsquared, 4)
    }
    regression_results.append(result)

# Create DataFrame for side-by-side comparison
regression_comparison = pd.DataFrame(regression_results)

# Display the summary table
print("=== Comparison of Group Effects on Social Visibility and Citations ===")
display(regression_comparison)


# === Plot: Comparison of R-squared for Social Visibility and Citation ===

# Create a long format DataFrame
r_squared_long = regression_comparison.melt(
    id_vars='Grouping Variable',
    value_vars=['Visibility R-squared', 'Citation R-squared'],
    var_name='Outcome',
    value_name='R_squared'
)

# Plot
plot_barplot(
    data=r_squared_long,
    x_col='Grouping Variable',
    y_col='R_squared',
    hue_col='Outcome',
    title='Comparison of R-squared Values: Social Visibility vs Citation',
    xlabel='Grouping Variable',
    ylabel='R-squared',
    palette='Dark2',
    format_yaxis=False,
    rot=0  # keep x-labels horizontal
)





import statsmodels.formula.api as smf

# Gender: Visibility (stot_log1p)
model_gender_visibility = smf.ols('stot_log1p ~ C(gender_majority)', data=df_gender_filtered).fit()
gender_regression_summary_visibility = pd.DataFrame({
    'Variable': model_gender_visibility.params.index,
    'Coef_Visibility': model_gender_visibility.params.values,
    'Pval_Visibility': model_gender_visibility.pvalues.values
}).round(4)

# Gender: Citation (cit_log)
model_gender_citation = smf.ols('cit_log ~ C(gender_majority)', data=df_gender_filtered).fit()
gender_regression_summary_citation = pd.DataFrame({
    'Variable': model_gender_citation.params.index,
    'Coef_Citation': model_gender_citation.params.values,
    'Pval_Citation': model_gender_citation.pvalues.values
}).round(4)

# Ethnicity: Visibility
model_ethnicity_visibility = smf.ols('stot_log1p ~ C(ethnicity_majority)', data=df_ranked_only).fit()
ethnicity_regression_summary_visibility = pd.DataFrame({
    'Variable': model_ethnicity_visibility.params.index,
    'Coef_Visibility': model_ethnicity_visibility.params.values,
    'Pval_Visibility': model_ethnicity_visibility.pvalues.values
}).round(4)

# Ethnicity: Citation
model_ethnicity_citation = smf.ols('cit_log ~ C(ethnicity_majority)', data=df_ranked_only).fit()
ethnicity_regression_summary_citation = pd.DataFrame({
    'Variable': model_ethnicity_citation.params.index,
    'Coef_Citation': model_ethnicity_citation.params.values,
    'Pval_Citation': model_ethnicity_citation.pvalues.values
}).round(4)

# Rank: Visibility
model_rank_visibility = smf.ols('stot_log1p ~ C(rank_group)', data=df_ranked_only).fit()
rank_regression_summary_visibility = pd.DataFrame({
    'Variable': model_rank_visibility.params.index,
    'Coef_Visibility': model_rank_visibility.params.values,
    'Pval_Visibility': model_rank_visibility.pvalues.values
}).round(4)

# Rank: Citation
model_rank_citation = smf.ols('cit_log ~ C(rank_group)', data=df_ranked_only).fit()
rank_regression_summary_citation = pd.DataFrame({
    'Variable': model_rank_citation.params.index,
    'Coef_Citation': model_rank_citation.params.values,
    'Pval_Citation': model_rank_citation.pvalues.values
}).round(4)


# Merging visibility and citation regression summaries
merged_gender = pd.merge(
    gender_regression_summary_visibility,
    gender_regression_summary_citation,
    on='Variable',
    suffixes=('_Visibility', '_Citation')
)

merged_ethnicity = pd.merge(
    ethnicity_regression_summary_visibility,
    ethnicity_regression_summary_citation,
    on='Variable',
    suffixes=('_Visibility', '_Citation')
)

merged_rank = pd.merge(
    rank_regression_summary_visibility,
    rank_regression_summary_citation,
    on='Variable',
    suffixes=('_Visibility', '_Citation')
)

# Compute Delta: how much citation differs *after* visibility
merged_gender['Delta (Citation - Visibility)'] = (
    merged_gender['Coef_Citation'] - merged_gender['Coef_Visibility']
)
merged_ethnicity['Delta (Citation - Visibility)'] = (
    merged_ethnicity['Coef_Citation'] - merged_ethnicity['Coef_Visibility']
)
merged_rank['Delta (Citation - Visibility)'] = (
    merged_rank['Coef_Citation'] - merged_rank['Coef_Visibility']
)

# Display the results
print("=== Gender Differences (Citation minus Visibility) ===")
display(merged_gender[['Variable', 'Coef_Visibility', 'Coef_Citation', 'Delta (Citation - Visibility)']])

print("\n=== Ethnicity Differences (Citation minus Visibility) ===")
display(merged_ethnicity[['Variable', 'Coef_Visibility', 'Coef_Citation', 'Delta (Citation - Visibility)']])

print("\n=== Rank Group Differences (Citation minus Visibility) ===")
display(merged_rank[['Variable', 'Coef_Visibility', 'Coef_Citation', 'Delta (Citation - Visibility)']])



# Extract intercepts for both visibility and citation
intercept_vis = merged_gender.loc[merged_gender['Variable'] == 'Intercept', 'Coef_Visibility'].values[0]
intercept_cit = merged_gender.loc[merged_gender['Variable'] == 'Intercept', 'Coef_Citation'].values[0]

# Manually compute predicted values for each gender group
gender_predicted = pd.DataFrame({
    'Gender': ['gender_female_majority', 'gender_male_majority'],
    'Visibility': [
        intercept_vis,
        intercept_vis + merged_gender.loc[
            merged_gender['Variable'] == 'C(gender_majority)[T.gender_male_majority]',
            'Coef_Visibility'
        ].values[0]
    ],
    'Citation': [
        intercept_cit,
        intercept_cit + merged_gender.loc[
            merged_gender['Variable'] == 'C(gender_majority)[T.gender_male_majority]',
            'Coef_Citation'
        ].values[0]
    ]
})

# Reorder columns for correct causal order: Visibility first, then Citation
gender_predicted = gender_predicted[['Gender', 'Visibility', 'Citation']]

# Melt dataframe for plotting
gender_predicted_melted = gender_predicted.melt(
    id_vars='Gender',
    var_name='Outcome',
    value_name='Predicted_Value'
)

# Plot predicted values
import matplotlib.pyplot as plt

plt.figure(figsize=(8, 6))

for gender in gender_predicted['Gender']:
    subset = gender_predicted_melted[gender_predicted_melted['Gender'] == gender]
    plt.plot(
        subset['Outcome'],
        subset['Predicted_Value'],
        marker='o',
        label=gender
    )

plt.title('Predicted Citation (after Visibility) by Gender Majority')
plt.ylabel('Predicted log(1 + value)')
plt.xlabel('Outcome (Visibility → Citation)')
plt.grid(True)
plt.legend(title='Gender Majority')
plt.tight_layout()

save_current_figure()

plt.show()


# Get regression intercepts for ethnicity
intercept_vis_eth = merged_ethnicity.loc[
    merged_ethnicity['Variable'] == 'Intercept', 'Coef_Visibility'
].values[0]

intercept_cit_eth = merged_ethnicity.loc[
    merged_ethnicity['Variable'] == 'Intercept', 'Coef_Citation'
].values[0]

# Extract dummy-coded ethnicity levels
dummy_rows = merged_ethnicity[merged_ethnicity['Variable'] != 'Intercept']
eth_levels = dummy_rows['Variable'].str.extract(r'\[T\.(.*)\]')[0].tolist()

# Find the baseline ethnicity level (not present in dummy terms)
all_levels = df_ranked_only['ethnicity_majority'].unique().tolist()
baseline_eth = [lvl for lvl in all_levels if lvl not in eth_levels][0]

# Compute predicted values for visibility and citation
eth_pred = pd.DataFrame({
    'Ethnicity': [baseline_eth] + eth_levels,
    'Visibility': [intercept_vis_eth] + [
        intercept_vis_eth + merged_ethnicity.loc[
            merged_ethnicity['Variable'] == f"C(ethnicity_majority)[T.{lvl}]",
            'Coef_Visibility'
        ].values[0] for lvl in eth_levels
    ],
    'Citation': [intercept_cit_eth] + [
        intercept_cit_eth + merged_ethnicity.loc[
            merged_ethnicity['Variable'] == f"C(ethnicity_majority)[T.{lvl}]",
            'Coef_Citation'
        ].values[0] for lvl in eth_levels
    ]
})

# Reorder columns for causal order: Visibility → Citation
eth_pred = eth_pred[['Ethnicity', 'Visibility', 'Citation']]

# Melt for plotting
eth_pred_melt = eth_pred.melt(
    id_vars='Ethnicity',
    var_name='Outcome',
    value_name='Predicted_Value'
)

# Plot predicted values
plt.figure(figsize=(10, 6))
for eth in eth_pred['Ethnicity']:
    sub = eth_pred_melt[eth_pred_melt['Ethnicity'] == eth]
    plt.plot(sub['Outcome'], sub['Predicted_Value'], marker='o', label=eth)

plt.title('Predicted Citation (after Visibility) by Ethnicity')
plt.xlabel('Outcome (Visibility → Citation)')
plt.ylabel('Predicted log(1 + value)')
plt.legend(title='Ethnicity', bbox_to_anchor=(1.05, 1), loc='upper left')
plt.tight_layout()

save_current_figure()

plt.show()


# Extract regression intercepts for university rank group
intercept_vis_rank = merged_rank.loc[
    merged_rank['Variable'] == 'Intercept', 'Coef_Visibility'
].values[0]

intercept_cit_rank = merged_rank.loc[
    merged_rank['Variable'] == 'Intercept', 'Coef_Citation'
].values[0]

# Extract dummy-coded rank levels (excluding baseline)
dummy_rows_r = merged_rank[merged_rank['Variable'] != 'Intercept']
rank_levels = dummy_rows_r['Variable'].str.extract(r'\[T\.(.*)\]')[0].tolist()

# Find the baseline rank group (not present among dummies)
all_ranks = df_ranked_only['rank_group'].cat.categories.tolist()
baseline_rank = [r for r in all_ranks if r not in rank_levels][0]

# Compute predicted values for each rank group
rank_pred = pd.DataFrame({
    'Rank Group': [baseline_rank] + rank_levels,
    'Visibility': [intercept_vis_rank] + [
        intercept_vis_rank + merged_rank.loc[
            merged_rank['Variable'] == f"C(rank_group)[T.{r}]",
            'Coef_Visibility'
        ].values[0] for r in rank_levels
    ],
    'Citation': [intercept_cit_rank] + [
        intercept_cit_rank + merged_rank.loc[
            merged_rank['Variable'] == f"C(rank_group)[T.{r}]",
            'Coef_Citation'
        ].values[0] for r in rank_levels
    ]
})

# Ensure correct column order for causal direction
rank_pred = rank_pred[['Rank Group', 'Visibility', 'Citation']]

# Melt for plotting
rank_pred_melt = rank_pred.melt(
    id_vars='Rank Group',
    var_name='Outcome',
    value_name='Predicted_Value'
)

# Plot predicted values
plt.figure(figsize=(10, 6))
for rg in rank_pred['Rank Group']:
    sub = rank_pred_melt[rank_pred_melt['Rank Group'] == rg]
    plt.plot(sub['Outcome'], sub['Predicted_Value'], marker='o', label=rg)

plt.title('Predicted Citation (after Visibility) by University Rank Group')
plt.xlabel('Outcome (Visibility → Citation)')
plt.ylabel('Predicted log(1 + value)')
plt.legend(title='Rank Group', bbox_to_anchor=(1.05, 1), loc='upper left')
plt.tight_layout()

save_current_figure()

plt.show()





# 4.1 Social visibility interaction: gender × rank_group
model_vis_inter = smf.ols(
    'stot_log1p ~ C(gender_majority) * C(rank_group)',
    data=df_ranked_gender_filtered  # filtered to drop "unknown"
).fit()

print("=== Interaction Model: Social Visibility ~ Gender Majority × Rank Group ===")
print(model_vis_inter.summary())


# 4.2 Citation interaction: gender × rank_group
model_cit_inter = smf.ols(
    'cit_log ~ C(gender_majority) * C(rank_group)',
    data=df_ranked_gender_filtered
).fit()

print("\n=== Interaction Model: Citations ~ Gender Majority × Rank Group ===")
print(model_cit_inter.summary())


# Ensure rank_group is treated in the right order
rank_order = ['top50', '51–100', '101–200', '201–500', '500+', '>1000']
df_ranked_gender_filtered['rank_group'] = pd.Categorical(
    df_ranked_gender_filtered['rank_group'],
    categories=rank_order,
    ordered=True
)

# 1) Build a grid of all combinations
genders = df_ranked_gender_filtered['gender_majority'].unique().tolist()
grid = pd.DataFrame(
    [(g, r) for g in genders for r in rank_order],
    columns=['gender_majority', 'rank_group']
)

# 2) Predict from your fitted interaction models
grid['pred_vis'] = model_vis_inter.predict(grid)
grid['pred_cit'] = model_cit_inter.predict(grid)

# 3) Plot predicted social visibility by rank for each gender
plt.figure(figsize=(8, 5))
sns.lineplot(
    data=grid,
    x='rank_group',
    y='pred_vis',
    hue='gender_majority',
    marker='o'
)
plt.title("Predicted Social Visibility by Gender Majority × Rank Group")
plt.xlabel("University Rank Group")
plt.ylabel("Predicted log(1 + Social Visibility)")
plt.legend(title="Gender Majority")
plt.tight_layout()
save_current_figure()
plt.show()

# 4) Plot predicted citation counts by rank for each gender
plt.figure(figsize=(8, 5))
sns.lineplot(
    data=grid,
    x='rank_group',
    y='pred_cit',
    hue='gender_majority',
    marker='o'
)
plt.title("Predicted Citations by Gender Majority × Rank Group")
plt.xlabel("University Rank Group")
plt.ylabel("Predicted log(1 + Citations)")
plt.legend(title="Gender Majority")
plt.tight_layout()
save_current_figure()
plt.show()


# Run interaction model for Social Visibility
model_vis_inter_ethnicity = smf.ols(
    'stot_log1p ~ C(ethnicity_majority) * C(rank_group)',
    data=df_ranked_only
).fit()

# Run interaction model for Citation
model_cit_inter_ethnicity = smf.ols(
    'cit_log ~ C(ethnicity_majority) * C(rank_group)',
    data=df_ranked_only
).fit()

# Print summaries if you want to see
print("=== Interaction model: Visibility ===")
print(model_vis_inter_ethnicity.summary())

print("\n=== Interaction model: Citation ===")
print(model_cit_inter_ethnicity.summary())


# Ensure rank_group has the proper order
rank_order = ['top50', '51–100', '101–200', '201–500', '500+', '>1000']
df_ranked_only['rank_group'] = pd.Categorical(
    df_ranked_only['rank_group'],
    categories=rank_order,
    ordered=True
)

# List of unique ethnicities
ethnicities = df_ranked_only['ethnicity_majority'].unique().tolist()

# Build a full combination grid
grid_ethnicity = pd.DataFrame(
    [(e, r) for e in ethnicities for r in rank_order],
    columns=['ethnicity_majority', 'rank_group']
)

# Predict using the interaction models
grid_ethnicity['pred_vis'] = model_vis_inter_ethnicity.predict(grid_ethnicity)
grid_ethnicity['pred_cit'] = model_cit_inter_ethnicity.predict(grid_ethnicity)

# Plot Predicted Social Visibility
plt.figure(figsize=(10, 6))
sns.lineplot(
    data=grid_ethnicity,
    x='rank_group',
    y='pred_vis',
    hue='ethnicity_majority',
    marker='o'
)
plt.title("Predicted Social Visibility by Ethnicity × Rank Group")
plt.xlabel("University Rank Group")
plt.ylabel("Predicted log(1 + Social Visibility)")
plt.legend(title="Ethnicity", bbox_to_anchor=(1.05, 1), loc='upper left')
plt.tight_layout()
save_current_figure()
plt.show()

# Plot Predicted Citations
plt.figure(figsize=(10, 6))
sns.lineplot(
    data=grid_ethnicity,
    x='rank_group',
    y='pred_cit',
    hue='ethnicity_majority',
    marker='o'
)
plt.title("Predicted Citations by Ethnicity × Rank Group")
plt.xlabel("University Rank Group")
plt.ylabel("Predicted log(1 + Citations)")
plt.legend(title="Ethnicity", bbox_to_anchor=(1.05, 1), loc='upper left')
plt.tight_layout()
save_current_figure()
plt.show()





# Get intercepts
intercept_vis_gender = merged_gender.loc[merged_gender['Variable'] == 'Intercept', 'Coef_Visibility'].values[0]
intercept_cit_gender = merged_gender.loc[merged_gender['Variable'] == 'Intercept', 'Coef_Citation'].values[0]

# Predicted values per gender
predicted_gender = pd.DataFrame({
    'Gender': ['Female majority', 'Male majority'],
    'Visibility': [
        intercept_vis_gender,
        intercept_vis_gender + merged_gender.loc[merged_gender['Variable'] == 'C(gender_majority)[T.gender_male_majority]', 'Coef_Visibility'].values[0]
    ],
    'Citation': [
        intercept_cit_gender,
        intercept_cit_gender + merged_gender.loc[merged_gender['Variable'] == 'C(gender_majority)[T.gender_male_majority]', 'Coef_Citation'].values[0]
    ]
})

# Melt to long format for plotting
predicted_gender_melted = predicted_gender.melt(
    id_vars='Gender',
    var_name='Outcome',
    value_name='Predicted_Value'
)

# Plot
plot_barplot(
    data=predicted_gender_melted,
    x_col='Gender',
    y_col='Predicted_Value',
    hue_col='Outcome',
    title='Predicted Mean Visibility and Citation by Gender',
    xlabel='Gender Majority',
    ylabel='Predicted log(1 + Value)',
    format_yaxis=False,
    rot=0
)


# Get intercepts
intercept_vis_eth = merged_ethnicity.loc[merged_ethnicity['Variable'] == 'Intercept', 'Coef_Visibility'].values[0]
intercept_cit_eth = merged_ethnicity.loc[merged_ethnicity['Variable'] == 'Intercept', 'Coef_Citation'].values[0]

# Extract all ethnicity rows (excluding Intercept)
eth_rows = merged_ethnicity[merged_ethnicity['Variable'] != 'Intercept'].copy()

# Clean variable names (e.g. C(...) → actual label)
eth_rows['Ethnicity'] = eth_rows['Variable'].str.extract(r'\[T\.(.*)\]')

# Build predicted value table
predicted_ethnicity = pd.DataFrame({
    'Ethnicity': ['Western/Northern'] + eth_rows['Ethnicity'].tolist(),
    'Visibility': [intercept_vis_eth] + (intercept_vis_eth + eth_rows['Coef_Visibility']).tolist(),
    'Citation': [intercept_cit_eth] + (intercept_cit_eth + eth_rows['Coef_Citation']).tolist()
})

# Melt to long format
predicted_ethnicity_melted = predicted_ethnicity.melt(
    id_vars='Ethnicity',
    var_name='Outcome',
    value_name='Predicted_Value'
)

# Plot
plot_barplot(
    data=predicted_ethnicity_melted,
    x_col='Ethnicity',
    y_col='Predicted_Value',
    hue_col='Outcome',
    title='Predicted Mean Visibility and Citation by Ethnicity',
    xlabel='Ethnicity Majority Group',
    ylabel='Predicted log(1 + Value)',
    format_yaxis=False,
    rot=45
)



# Get intercepts
intercept_vis_rank = merged_rank.loc[merged_rank['Variable'] == 'Intercept', 'Coef_Visibility'].values[0]
intercept_cit_rank = merged_rank.loc[merged_rank['Variable'] == 'Intercept', 'Coef_Citation'].values[0]

# Extract rows for rank_group (excluding Intercept)
rank_rows = merged_rank[merged_rank['Variable'] != 'Intercept'].copy()

# Clean variable names (e.g. C(...) → actual label)
rank_rows['Rank_Group'] = rank_rows['Variable'].str.extract(r'\[T\.(.*)\]')

# Build predicted value table
predicted_rank = pd.DataFrame({
    'Rank_Group': ['top50'] + rank_rows['Rank_Group'].tolist(),
    'Visibility': [intercept_vis_rank] + (intercept_vis_rank + rank_rows['Coef_Visibility']).tolist(),
    'Citation': [intercept_cit_rank] + (intercept_cit_rank + rank_rows['Coef_Citation']).tolist()
})

# Melt to long format
predicted_rank_melted = predicted_rank.melt(
    id_vars='Rank_Group',
    var_name='Outcome',
    value_name='Predicted_Value'
)

# Plot
plot_barplot(
    data=predicted_rank_melted,
    x_col='Rank_Group',
    y_col='Predicted_Value',
    hue_col='Outcome',
    title='Predicted Mean Visibility and Citation by University Rank',
    xlabel='Rank Group',
    ylabel='Predicted log(1 + Value)',
    format_yaxis=False,
    rot=45
)


# Delta (difference) plots ---

# Gender Delta
plot_barplot(
    data=merged_gender,
    x_col='Variable',
    y_col='Delta (Citation - Visibility)',
    title='Visibility vs Citation Difference (Gender Majority)',
    xlabel='Gender Variable',
    ylabel='Delta (Citation - Visibility)',
    format_yaxis=False,
    rot=45
)

# Ethnicity Delta
plot_barplot(
    data=merged_ethnicity,
    x_col='Variable',
    y_col='Delta (Citation - Visibility)',
    title='Visibility vs Citation Difference (Ethnicity)',
    xlabel='Ethnicity Variable',
    ylabel='Delta (Citation - Visibility)',
    format_yaxis=False,
    rot=45
)

# Rank Group Delta
plot_barplot(
    data=merged_rank,
    x_col='Variable',
    y_col='Delta (Citation - Visibility)',
    title='Visibility vs Citation Difference (Rank Group)',
    xlabel='Rank Group',
    ylabel='Delta (Citation - Visibility)',
    format_yaxis=False,
    rot=45
)



